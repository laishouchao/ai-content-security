# AI内容安全监控系统 - 集成测试指南

## 概述
本文档描述如何测试真实的前后端违规检测联动功能，确保系统只在真正检测到违规内容时才推送通知。

## 前后端联动流程

### 1. 系统架构
```
用户创建扫描任务 → 后端Celery异步处理 → AI分析引擎 → 违规检测 → WebSocket通知 → 前端UI弹窗
```

### 2. 关键组件

#### 后端组件
- **AI分析引擎** (`app/engines/ai_analysis.py`)
  - 使用OpenAI GPT-4 Vision分析页面截图
  - 严格的提示词，只在确凿证据下标记违规
  - 置信度阈值：60%以上才认为是真实违规

- **WebSocket通知处理器** (`app/websocket/handlers.py`)
  - 验证违规数据有效性
  - 置信度过滤：50%以下的检测结果不发送通知
  - 详细的违规信息构建

- **扫描任务处理器** (`app/tasks/scan_tasks.py`)
  - 只在高置信度违规时发送WebSocket通知
  - 包含完整的违规详情（域名、类型、风险等级、置信度）

#### 前端组件
- **WebSocket Store** (`frontend/src/stores/websocket.ts`)
  - 移除所有模拟数据和模拟连接
  - 只处理真实的后端WebSocket消息
  - 基于真实数据显示UI通知

## 测试步骤

### 1. 环境准备
1. 确保后端服务运行：
   ```bash
   docker-compose up -d postgres redis
   python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
   celery -A celery_app worker --loglevel=info
   ```

2. 确保前端服务运行：
   ```bash
   cd frontend
   npm run dev
   ```

3. 配置有效的OpenAI API密钥（在用户设置中）

### 2. 正面测试（应该触发通知）
1. 创建扫描任务，目标域名指向包含违规内容的网站
2. 观察任务执行过程
3. 当AI检测到违规时，应该看到：
   - 后端日志显示违规检测
   - WebSocket发送违规通知
   - 前端显示详细的违规弹窗

### 3. 负面测试（不应该触发通知）
1. 创建扫描任务，目标域名指向正常网站（如技术博客、企业官网）
2. 观察AI分析过程
3. 应该看到：
   - AI分析完成但未检测到违规
   - 没有WebSocket违规通知
   - 前端不显示违规相关弹窗

### 4. 边界测试
1. 测试低置信度场景：
   - AI返回置信度低于60%的结果
   - 系统应该不发送违规通知

2. 测试数据不完整场景：
   - 缺少截图文件的域名
   - 系统应该跳过AI分析

## 验证要点

### 后端验证
- [ ] AI分析只在有确凿证据时标记违规
- [ ] 置信度阈值正确工作（60%以上）
- [ ] WebSocket通知包含完整违规信息
- [ ] 没有模拟数据被发送

### 前端验证
- [ ] 只显示来自后端的真实违规通知
- [ ] 通知内容包含详细信息（域名、类型、风险等级、置信度）
- [ ] 没有定时的模拟消息推送
- [ ] WebSocket连接状态正确显示

### 系统验证
- [ ] 整个流程端到端工作
- [ ] 性能符合预期（不会因为严格验证而过慢）
- [ ] 错误处理正确（网络问题、API失败等）

## 监控和调试

### 日志查看
- 后端违规检测日志：查看AI分析结果和置信度
- WebSocket通知日志：确认通知发送情况
- 前端控制台：查看WebSocket消息接收情况

### 常见问题
1. **没有收到违规通知**
   - 检查AI配置是否正确
   - 确认置信度是否达到阈值
   - 查看后端日志中的分析结果

2. **收到太多误报**
   - 调整AI提示词模板
   - 提高置信度阈值
   - 检查分析的网站类型

3. **WebSocket连接问题**
   - 确认用户已登录并有有效token
   - 检查后端WebSocket服务状态
   - 查看网络连接

## 总结
本系统已完全移除模拟数据，建立了严格的违规检测标准。只有在AI明确检测到违规内容且置信度足够高时，才会触发前后端联动的违规通知流程。这确保了系统的准确性和实用性。