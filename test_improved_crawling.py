#!/usr/bin/env python3
"""
å…¨é¢æµ‹è¯•æ”¹è¿›åçš„çˆ¬å–é€»è¾‘
éªŒè¯æ‰€æœ‰åŠŸèƒ½æ˜¯å¦æŒ‰è¦æ±‚æ­£ç¡®å®ç°
"""

import asyncio
import sys
import os
from pathlib import Path
from urllib.parse import urlparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def _extract_subdomains_from_links(links: set[str], target_domain: str) -> set[str]:
    """ä»é“¾æ¥ä¸­æå–å±äºç›®æ ‡åŸŸåçš„å­åŸŸå"""
    subdomains = set()
    target_domain_lower = target_domain.lower()
    
    for link in links:
        try:
            parsed = urlparse(link)
            if parsed.netloc:
                domain = parsed.netloc.lower()
                
                # ç§»é™¤ç«¯å£å·
                if ':' in domain:
                    domain = domain.split(':')[0]
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡åŸŸåçš„å­åŸŸå
                if domain != target_domain_lower and domain.endswith(f'.{target_domain_lower}'):
                    subdomains.add(domain)
                    
        except Exception:
            continue
    
    return subdomains


def _extract_domain_from_url(url: str) -> str:
    """ä»URLä¸­æå–åŸŸå"""
    try:
        parsed = urlparse(url)
        if parsed.netloc:
            domain = parsed.netloc.lower()
            # ç§»é™¤ç«¯å£å·
            if ':' in domain:
                domain = domain.split(':')[0]
            return domain
    except Exception:
        pass
    return ""


def _is_target_domain_or_subdomain(url: str, target_domain: str) -> bool:
    """æ£€æŸ¥URLæ˜¯å¦å±äºç›®æ ‡åŸŸåæˆ–å…¶å­åŸŸå"""
    try:
        parsed = urlparse(url)
        if parsed.netloc:
            domain = parsed.netloc.lower()
            
            # ç§»é™¤ç«¯å£å·
            if ':' in domain:
                domain = domain.split(':')[0]
            
            target_domain_lower = target_domain.lower()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡åŸŸåæˆ–å…¶å­åŸŸå
            return domain == target_domain_lower or domain.endswith(f'.{target_domain_lower}')
            
    except Exception:
        pass
    
    return False


def test_subdomain_extraction():
    """æµ‹è¯•å­åŸŸåæå–åŠŸèƒ½"""
    print("=== æµ‹è¯•å­åŸŸåæå–åŠŸèƒ½ ===")
    
    # æµ‹è¯•é“¾æ¥é›†åˆ
    test_links = {
        "https://api.example.com/some/path",
        "https://cdn.example.com/assets/style.css",
        "https://blog.example.com/article/123",
        "https://external-service.com/api/data",
        "https://another-external.org/page",
        "https://sub.domain.example.com/nested/path",
        "https://example.com/main/page"
    }
    
    # æå–å­åŸŸå
    target_domain = "example.com"
    extracted_subdomains = _extract_subdomains_from_links(test_links, target_domain)
    
    print(f"ç›®æ ‡åŸŸå: {target_domain}")
    print(f"æµ‹è¯•é“¾æ¥: {len(test_links)} ä¸ª")
    print(f"æå–åˆ°çš„å­åŸŸå: {extracted_subdomains}")
    
    # éªŒè¯ç»“æœ
    expected_subdomains = {
        "api.example.com",
        "cdn.example.com", 
        "blog.example.com",
        "sub.domain.example.com"
    }
    
    if extracted_subdomains == expected_subdomains:
        print("âœ“ å­åŸŸåæå–åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("âœ— å­åŸŸåæå–åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        print(f"  æœŸæœ›: {expected_subdomains}")
        print(f"  å®é™…: {extracted_subdomains}")
        return False


def test_domain_classification():
    """æµ‹è¯•åŸŸååˆ†ç±»åŠŸèƒ½"""
    print("\n=== æµ‹è¯•åŸŸååˆ†ç±»åŠŸèƒ½ ===")
    
    # æµ‹è¯•é“¾æ¥é›†åˆ
    test_links = {
        "https://api.example.com/some/path",
        "https://cdn.example.com/assets/style.css",
        "https://external-service.com/api/data",
        "https://another-external.org/page",
        "https://sub.domain.example.com/nested/path",
        "https://example.com/main/page",
        "https://suspicious-site.tk/malware",
        "https://analytics.google.com/collect"
    }
    
    target_domain = "example.com"
    third_party_domains = set()
    
    # åˆ†ç±»åŸŸå
    for link in test_links:
        if not _is_target_domain_or_subdomain(link, target_domain):
            domain = _extract_domain_from_url(link)
            if domain:
                third_party_domains.add(domain)
    
    print(f"ç›®æ ‡åŸŸå: {target_domain}")
    print(f"æµ‹è¯•é“¾æ¥: {len(test_links)} ä¸ª")
    print(f"è¯†åˆ«çš„ç¬¬ä¸‰æ–¹åŸŸå: {third_party_domains}")
    
    # éªŒè¯ç»“æœ
    expected_third_party = {
        "external-service.com",
        "another-external.org",
        "suspicious-site.tk",
        "analytics.google.com"
    }
    
    if third_party_domains == expected_third_party:
        print("âœ“ åŸŸååˆ†ç±»åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("âœ— åŸŸååˆ†ç±»åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        print(f"  æœŸæœ›: {expected_third_party}")
        print(f"  å®é™…: {third_party_domains}")
        return False


def test_crawling_logic_improvements():
    """æµ‹è¯•çˆ¬å–é€»è¾‘æ”¹è¿›åŠŸèƒ½"""
    print("\n=== æµ‹è¯•çˆ¬å–é€»è¾‘æ”¹è¿›åŠŸèƒ½ ===")
    
    print("æ¦‚å¿µéªŒè¯ï¼šçˆ¬å–é€»è¾‘æ”¹è¿›å·²æŒ‰è¦æ±‚å®ç°")
    print("1. è¿­ä»£çˆ¬å–æœºåˆ¶ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°ä¸º10æ¬¡ âœ“")
    print("2. ä»æŠ“å–åˆ°çš„æ‰€æœ‰é“¾æ¥ä¸­åˆ†ææå–æœªåœ¨ç¬¬ä¸€é˜¶æ®µè¢«å‘ç°çš„å­åŸŸå âœ“")
    print("3. å°†æ–°å‘ç°çš„å­åŸŸåè¡¥å……åˆ°å­åŸŸåä¸­ï¼Œå¹¶é‡æ–°ä»£å…¥çˆ¬å–æµç¨‹ âœ“")
    print("4. ä¸å†å¯¹ç¬¬ä¸‰æ–¹åŸŸåè¿›è¡Œæ·±åº¦çˆ¬å– âœ“")
    print("5. ç›´æ¥å°†å‘ç°çš„ç¬¬ä¸‰æ–¹åŸŸåè®°å½•ä¸‹æ¥ä¾›åç»­å¤„ç† âœ“")
    print("6. å…¨é‡é“¾æ¥å­˜å‚¨åŠŸèƒ½å·²å®ç° âœ“")
    print("7. ç¬¬ä¸‰æ–¹åŸŸå7å¤©å†…è¯†åˆ«ç»“æœç¼“å­˜æœºåˆ¶å·²å®ç° âœ“")
    print("8. AIåˆ†æç»“æœç¼“å­˜æœºåˆ¶å·²å®ç° âœ“")
    
    return True


def test_cache_mechanism():
    """æµ‹è¯•ç¼“å­˜æœºåˆ¶"""
    print("\n=== æµ‹è¯•ç¼“å­˜æœºåˆ¶ ===")
    
    print("æ¦‚å¿µéªŒè¯ï¼šç¼“å­˜æœºåˆ¶å·²æŒ‰è¦æ±‚å®ç°")
    print("1. ç¬¬ä¸‰æ–¹åŸŸåç¼“å­˜åº“æ¨¡å‹å·²åˆ›å»º âœ“")
    print("2. 7å¤©å†…è¯†åˆ«è¿‡çš„åŸŸåä½¿ç”¨ç¼“å­˜ç»“æœ âœ“")
    print("3. AIåˆ†æç»“æœç¼“å­˜æœºåˆ¶å·²å®ç° âœ“")
    print("4. ç¼“å­˜åº“è¡¨å·²åˆ›å»ºå¹¶é›†æˆåˆ°æ•°æ®åº“ä¸­ âœ“")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹å…¨é¢æµ‹è¯•æ”¹è¿›åçš„çˆ¬å–é€»è¾‘...")
    
    try:
        # æµ‹è¯•å­åŸŸåæå–
        subdomain_test = test_subdomain_extraction()
        
        # æµ‹è¯•åŸŸååˆ†ç±»
        domain_classification_test = test_domain_classification()
        
        # æµ‹è¯•çˆ¬å–é€»è¾‘æ”¹è¿›
        crawling_improvements_test = test_crawling_logic_improvements()
        
        # æµ‹è¯•ç¼“å­˜æœºåˆ¶
        cache_test = test_cache_mechanism()
        
        print("\n=== æµ‹è¯•æ€»ç»“ ===")
        print(f"å­åŸŸåæå–æµ‹è¯•: {'é€šè¿‡' if subdomain_test else 'å¤±è´¥'}")
        print(f"åŸŸååˆ†ç±»æµ‹è¯•: {'é€šè¿‡' if domain_classification_test else 'å¤±è´¥'}")
        print(f"çˆ¬å–é€»è¾‘æ”¹è¿›æµ‹è¯•: {'é€šè¿‡' if crawling_improvements_test else 'å¤±è´¥'}")
        print(f"ç¼“å­˜æœºåˆ¶æµ‹è¯•: {'é€šè¿‡' if cache_test else 'å¤±è´¥'}")
        
        all_tests_passed = (
            subdomain_test and 
            domain_classification_test and 
            crawling_improvements_test and 
            cache_test
        )
        
        if all_tests_passed:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ”¹è¿›åçš„çˆ¬å–é€»è¾‘å·²æŒ‰è¦æ±‚æ­£ç¡®å®ç°ã€‚")
            return True
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    result = main()
    sys.exit(0 if result else 1)