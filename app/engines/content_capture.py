import asyncio
import aiohttp
import time
import os
from typing import List, Dict, Optional, Any, Tuple
from urllib.parse import urlparse
from datetime import datetime
import hashlib
import base64
from pathlib import Path

from playwright.async_api import async_playwright, Browser, BrowserContext, Page
from bs4 import BeautifulSoup

from app.core.logging import TaskLogger
from app.core.config import settings
from app.engines.optimized_screenshot_service import OptimizedScreenshotService


class ContentResult:
    """å†…å®¹æŠ“å–ç»“æœ"""
    
    def __init__(self, url: str, domain: str):
        self.url = url
        self.domain = domain
        self.html_content = ""
        self.text_content = ""
        self.page_title = ""
        self.meta_description = ""
        self.screenshot_path = ""
        self.content_hash = ""
        self.file_size = 0
        self.status_code = None  # type: Optional[int]
        self.error_message = ""
        self.captured_at = datetime.utcnow()
        self.capture_duration = 0.0  # type: float
    
    def set_content_hash(self, content: str):
        """è®¾ç½®å†…å®¹å“ˆå¸Œ"""
        self.content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()


class ScreenshotService:
    """æˆªå›¾æœåŠ¡"""
    
    def __init__(self, task_id: str):
        self.task_id = task_id
        self.screenshot_dir = Path(settings.SCREENSHOT_PATH) / task_id
        self.screenshot_dir.mkdir(parents=True, exist_ok=True)
        
        self.browser = None
        self.context = None
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.playwright = await async_playwright().start()
        
        # å¯åŠ¨æµè§ˆå™¨
        self.browser = await self.playwright.chromium.launch(
            headless=settings.PLAYWRIGHT_HEADLESS,
            args=[
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-accelerated-2d-canvas',
                '--disable-gpu',
                '--window-size=1920,1080'
            ]
        )
        
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        self.context = await self.browser.new_context(
            viewport={
                'width': settings.SCREENSHOT_VIEWPORT_WIDTH,
                'height': settings.SCREENSHOT_VIEWPORT_HEIGHT
            },
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        )
        
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        if self.context:
            await self.context.close()
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
    
    async def capture_screenshot(self, url: str, filename: Optional[str] = None) -> Tuple[str, str]:
        """æˆªå–é¡µé¢æˆªå›¾"""
        if not filename:
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_domain = self._make_safe_filename(urlparse(url).netloc)
            timestamp = int(time.time())
            filename = f"{safe_domain}_{timestamp}.png"
        
        screenshot_path = self.screenshot_dir / filename
        
        page = None
        try:
            # æ£€æŸ¥contextæ˜¯å¦å·²åˆå§‹åŒ–
            if self.context is None:
                raise Exception("æµè§ˆå™¨ä¸Šä¸‹æ–‡æœªåˆå§‹åŒ–")
                
            page = await self.context.new_page()
            
            # è®¾ç½®è¶…æ—¶
            page.set_default_timeout(settings.PLAYWRIGHT_TIMEOUT)
            
            # è®¿é—®é¡µé¢
            response = await page.goto(url, wait_until='networkidle')
            
            if response and response.status >= 400:
                raise Exception(f"é¡µé¢è¿”å›é”™è¯¯çŠ¶æ€: {response.status}")
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            await page.wait_for_load_state('networkidle')
            await asyncio.sleep(2)  # é¢å¤–ç­‰å¾…æ—¶é—´ç¡®ä¿åŠ¨æ€å†…å®¹åŠ è½½
            
            # æˆªå›¾
            await page.screenshot(
                path=str(screenshot_path),
                full_page=True,
                type='png'
            )
            
            # è·å–é¡µé¢HTMLå†…å®¹
            html_content = await page.content()
            
            return str(screenshot_path), html_content
            
        except Exception as e:
            # å¦‚æœæˆªå›¾å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªé”™è¯¯æˆªå›¾
            error_screenshot = await self._create_error_screenshot(url, str(e))
            return error_screenshot, ""
            
        finally:
            if page:
                await page.close()
    
    async def _create_error_screenshot(self, url: str, error_message: str) -> str:
        """åˆ›å»ºé”™è¯¯æˆªå›¾"""
        safe_domain = self._make_safe_filename(urlparse(url).netloc)
        timestamp = int(time.time())
        filename = f"{safe_domain}_{timestamp}_error.png"
        screenshot_path = self.screenshot_dir / filename
        
        try:
            # æ£€æŸ¥contextæ˜¯å¦å·²åˆå§‹åŒ–
            if self.context is None:
                raise Exception("æµè§ˆå™¨ä¸Šä¸‹æ–‡æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ›å»ºé”™è¯¯æˆªå›¾")
                
            page = await self.context.new_page()
            
            # åˆ›å»ºé”™è¯¯é¡µé¢HTML
            error_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Screenshot Error</title>
                <style>
                    body {{ font-family: Arial, sans-serif; padding: 50px; background: #f5f5f5; }}
                    .error-container {{ background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                    .error-title {{ color: #d32f2f; font-size: 24px; margin-bottom: 20px; }}
                    .error-url {{ background: #f0f0f0; padding: 10px; border-radius: 5px; word-break: break-all; }}
                    .error-message {{ color: #666; margin-top: 15px; }}
                </style>
            </head>
            <body>
                <div class="error-container">
                    <div class="error-title">é¡µé¢æˆªå›¾å¤±è´¥</div>
                    <div class="error-url">{url}</div>
                    <div class="error-message">é”™è¯¯ä¿¡æ¯: {error_message}</div>
                    <div class="error-message">æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>
                </div>
            </body>
            </html>
            """
            
            await page.set_content(error_html)
            await page.screenshot(path=str(screenshot_path), type='png')
            await page.close()
            
        except Exception:
            pass
        
        return str(screenshot_path)
    
    def _make_safe_filename(self, filename: str) -> str:
        """ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å"""
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨çš„å­—ç¬¦
        safe_chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_."
        safe_filename = ''.join(c if c in safe_chars else '_' for c in filename)
        
        # é™åˆ¶é•¿åº¦
        if len(safe_filename) > 50:
            safe_filename = safe_filename[:50]
        
        return safe_filename or "unknown"


class ContentExtractor:
    """å†…å®¹æå–å™¨"""
    
    def __init__(self):
        pass
    
    def extract_text_content(self, html: str) -> Dict[str, str]:
        """ä»HTMLä¸­æå–æ–‡æœ¬å†…å®¹"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
            for script in soup(["script", "style"]):
                script.decompose()
            
            # æå–é¡µé¢æ ‡é¢˜
            title = ""
            title_tag = soup.find('title')
            if title_tag:
                title = title_tag.get_text().strip()
            
            # æå–metaæè¿°
            meta_description = ""
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            # æ£€æŸ¥meta_descæ˜¯å¦ä¸ºTagç±»å‹
            from bs4 import Tag
            if isinstance(meta_desc, Tag):
                content_value = meta_desc.get('content')
                if content_value is not None:
                    # ç¡®ä¿content_valueæ˜¯å­—ç¬¦ä¸²ç±»å‹
                    if isinstance(content_value, str):
                        meta_description = content_value.strip()
                    elif isinstance(content_value, list) and len(content_value) > 0:
                        meta_description = content_value[0].strip()
            
            # æå–æ­£æ–‡å†…å®¹
            text_content = soup.get_text()
            
            # æ¸…ç†æ–‡æœ¬
            lines = (line.strip() for line in text_content.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text_content = ' '.join(chunk for chunk in chunks if chunk)
            
            # é™åˆ¶å†…å®¹é•¿åº¦
            max_length = 50000  # 50KBæ–‡æœ¬
            if len(text_content) > max_length:
                text_content = text_content[:max_length] + "... [å†…å®¹è¿‡é•¿å·²æˆªæ–­]"
            
            return {
                'title': title,
                'meta_description': meta_description,
                'text_content': text_content
            }
            
        except Exception as e:
            return {
                'title': "",
                'meta_description': "",
                'text_content': f"å†…å®¹æå–å¤±è´¥: {str(e)}"
            }


class ContentCaptureEngine:
    """å†…å®¹æŠ“å–å¼•æ“"""
    
    def __init__(self, task_id: str, user_id: str):
        self.task_id = task_id
        self.user_id = user_id
        self.logger = TaskLogger(task_id, user_id)
        
        self.content_extractor = ContentExtractor()
        self.captured_count = 0
        self.failed_count = 0
    
    async def capture_domain_content(
        self, 
        domain: str, 
        urls: List[str], 
        config: Dict[str, Any]
    ) -> List[ContentResult]:
        """æŠ“å–åŸŸåå†…å®¹"""
        start_time = time.time()
        self.logger.info(f"ğŸš€ å¼€å§‹æŠ“å–åŸŸåå†…å®¹: {domain}, {len(urls)} ä¸ªURL")
        
        results = []
        max_captures = config.get('max_captures_per_domain', 50)
        capture_screenshots = config.get('capture_screenshots', True)
        
        self.logger.info(f"ğŸ“¸ æˆªå›¾é…ç½®: capture_screenshots={capture_screenshots}")
        
        # é™åˆ¶æŠ“å–æ•°é‡
        urls_to_capture = urls[:max_captures]
        self.logger.info(f"ğŸ“‹ å‡†å¤‡æŠ“å– {len(urls_to_capture)} ä¸ªURL")
        
        # ä½¿ç”¨ä¼˜åŒ–çš„æˆªå›¾æœåŠ¡
        if capture_screenshots:
            try:
                self.logger.info("ğŸ”§ åˆå§‹åŒ–ä¼˜åŒ–æˆªå›¾æœåŠ¡...")
                async with OptimizedScreenshotService(self.task_id, self.user_id) as optimized_service:
                    # æå–åŸŸååˆ—è¡¨ï¼Œæ¯ä¸ªåŸŸååªæˆªå›¾ä¸€å¼ 
                    unique_domains = list(set([urlparse(url).netloc for url in urls_to_capture]))
                    self.logger.info(f"ğŸŒ å‘ç° {len(unique_domains)} ä¸ªå”¯ä¸€åŸŸå: {unique_domains}")
                    
                    # ä¼˜åŒ–æˆªå›¾
                    self.logger.info("ğŸ“¸ å¼€å§‹æ‰¹é‡æˆªå›¾...")
                    screenshot_results = await optimized_service.capture_domains_optimized(
                        unique_domains, config
                    )
                    
                    self.logger.info(f"ğŸ“Š æˆªå›¾ç»“æœ: {len(screenshot_results)} ä¸ª")
                    
                    # è½¬æ¢ä¸ºContentResultæ ¼å¼
                    for i, screenshot_result in enumerate(screenshot_results):
                        self.logger.debug(f"å¤„ç†æˆªå›¾ç»“æœ {i+1}/{len(screenshot_results)}: {screenshot_result.domain}")
                        
                        if screenshot_result.success:
                            content_result = ContentResult(screenshot_result.url, screenshot_result.domain)
                            content_result.screenshot_path = screenshot_result.screenshot_path
                            content_result.html_content = screenshot_result.text_content  # ä½¿ç”¨æå–çš„æ–‡æœ¬
                            content_result.page_title = screenshot_result.page_title
                            content_result.meta_description = screenshot_result.page_description
                            content_result.text_content = screenshot_result.text_content
                            content_result.set_content_hash(screenshot_result.text_content)
                            content_result.file_size = screenshot_result.file_size
                            content_result.status_code = 200
                            content_result.capture_duration = time.time() - start_time
                            
                            self.logger.info(f"âœ… æˆåŠŸæŠ“å–: {screenshot_result.domain} - æˆªå›¾è·¯å¾„: {screenshot_result.screenshot_path}")
                            results.append(content_result)
                            self.captured_count += 1
                        else:
                            # ä¸ºå¤±è´¥çš„åŸŸååˆ›å»ºé”™è¯¯ç»“æœ
                            content_result = ContentResult(screenshot_result.url, screenshot_result.domain)
                            content_result.error_message = screenshot_result.error_message
                            content_result.status_code = 500
                            
                            self.logger.warning(f"âŒ æŠ“å–å¤±è´¥: {screenshot_result.domain} - é”™è¯¯: {screenshot_result.error_message}")
                            results.append(content_result)
                            self.failed_count += 1
                            
            except Exception as e:
                self.logger.error(f"ğŸ’¥ æˆªå›¾æœåŠ¡å¼‚å¸¸: {e}")
                import traceback
                self.logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                
                # å¦‚æœæˆªå›¾æœåŠ¡å¤±è´¥ï¼Œå°è¯•ä¸æˆªå›¾çš„æ–¹å¼
                self.logger.info("ğŸ”„ æˆªå›¾æœåŠ¡å¤±è´¥ï¼Œå°è¯•ä¸æˆªå›¾çš„æ–¹å¼...")
                results = await self._capture_without_screenshots(
                    urls_to_capture, domain, config
                )
        else:
            self.logger.info("ğŸ“ ä»…æŠ“å–å†…å®¹ï¼Œä¸æˆªå›¾")
            results = await self._capture_without_screenshots(
                urls_to_capture, domain, config
            )
        
        duration = time.time() - start_time
        self.logger.info(f"ğŸ åŸŸåå†…å®¹æŠ“å–å®Œæˆ: æˆåŠŸ {self.captured_count}, å¤±è´¥ {self.failed_count}, è€—æ—¶ {duration:.2f} ç§’")
        
        # è¾“å‡ºè¯¦ç»†çš„ç»“æœç»Ÿè®¡
        for result in results:
            self.logger.debug(f"ç»“æœè¯¦æƒ…: {result.domain} - æˆªå›¾è·¯å¾„: {result.screenshot_path} - çŠ¶æ€: {result.status_code}")
        
        return results
    
    async def _capture_with_screenshots(
        self, 
        urls: List[str], 
        domain: str, 
        screenshot_service: ScreenshotService,
        config: Dict[str, Any]
    ) -> List[ContentResult]:
        """ä½¿ç”¨æˆªå›¾æœåŠ¡æŠ“å–å†…å®¹"""
        results = []
        
        # é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(3)  # æˆªå›¾æ¯”è¾ƒæ¶ˆè€—èµ„æºï¼Œé™åˆ¶å¹¶å‘æ•°
        
        async def capture_single_url(url: str):
            async with semaphore:
                return await self._capture_single_page_with_screenshot(
                    url, domain, screenshot_service, config
                )
        
        # æ‰¹é‡æŠ“å–
        tasks = [capture_single_url(url) for url in urls]
        capture_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        for result in capture_results:
            if isinstance(result, ContentResult):
                results.append(result)
                if result.error_message:
                    self.failed_count += 1
                else:
                    self.captured_count += 1
            elif isinstance(result, Exception):
                self.logger.debug(f"å†…å®¹æŠ“å–å¼‚å¸¸: {result}")
                self.failed_count += 1
        
        return results
    
    async def _capture_without_screenshots(
        self, 
        urls: List[str], 
        domain: str, 
        config: Dict[str, Any]
    ) -> List[ContentResult]:
        """ä¸ä½¿ç”¨æˆªå›¾æœåŠ¡æŠ“å–å†…å®¹"""
        results = []
        
        # é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(10)
        
        async def capture_single_url(url: str):
            async with semaphore:
                return await self._capture_single_page_without_screenshot(
                    url, domain, config
                )
        
        # æ‰¹é‡æŠ“å–
        tasks = [capture_single_url(url) for url in urls]
        capture_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        for result in capture_results:
            if isinstance(result, ContentResult):
                results.append(result)
                if result.error_message:
                    self.failed_count += 1
                else:
                    self.captured_count += 1
            elif isinstance(result, Exception):
                self.logger.debug(f"å†…å®¹æŠ“å–å¼‚å¸¸: {result}")
                self.failed_count += 1
        
        return results
    
    async def _capture_single_page_with_screenshot(
        self, 
        url: str, 
        domain: str, 
        screenshot_service: ScreenshotService,
        config: Dict[str, Any]
    ) -> ContentResult:
        """æŠ“å–å•ä¸ªé¡µé¢ï¼ˆåŒ…å«æˆªå›¾ï¼‰"""
        start_time = time.time()
        result = ContentResult(url, domain)
        
        try:
            # æˆªå›¾å¹¶è·å–HTMLå†…å®¹
            screenshot_path, html_content = await screenshot_service.capture_screenshot(url)
            
            result.screenshot_path = screenshot_path
            result.html_content = html_content
            result.capture_duration = time.time() - start_time
            
            if html_content:
                # æå–æ–‡æœ¬å†…å®¹
                extracted = self.content_extractor.extract_text_content(html_content)
                result.page_title = extracted['title']
                result.meta_description = extracted['meta_description']
                result.text_content = extracted['text_content']
                result.set_content_hash(html_content)
                
                # è®¡ç®—æ–‡ä»¶å¤§å°
                if os.path.exists(screenshot_path):
                    result.file_size = os.path.getsize(screenshot_path)
                
                result.status_code = 200
                self.logger.debug(f"é¡µé¢å†…å®¹æŠ“å–æˆåŠŸ: {url}")
            else:
                result.error_message = "æ— æ³•è·å–é¡µé¢å†…å®¹"
                result.status_code = 500
                
        except Exception as e:
            result.error_message = f"æŠ“å–å¤±è´¥: {str(e)}"
            result.capture_duration = time.time() - start_time
            self.logger.debug(f"é¡µé¢å†…å®¹æŠ“å–å¤±è´¥: {url} - {e}")
        
        return result
    
    async def _capture_single_page_without_screenshot(
        self, 
        url: str, 
        domain: str, 
        config: Dict[str, Any]
    ) -> ContentResult:
        """æŠ“å–å•ä¸ªé¡µé¢ï¼ˆä¸åŒ…å«æˆªå›¾ï¼‰"""
        start_time = time.time()
        result = ContentResult(url, domain)
        
        try:
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as response:
                    result.status_code = response.status
                    result.capture_duration = time.time() - start_time
                    
                    if response.status == 200:
                        html_content = await response.text()
                        result.html_content = html_content
                        
                        # æå–æ–‡æœ¬å†…å®¹
                        extracted = self.content_extractor.extract_text_content(html_content)
                        result.page_title = extracted['title']
                        result.meta_description = extracted['meta_description']
                        result.text_content = extracted['text_content']
                        result.set_content_hash(html_content)
                        
                        self.logger.debug(f"é¡µé¢å†…å®¹æŠ“å–æˆåŠŸ: {url}")
                    else:
                        result.error_message = f"HTTPé”™è¯¯: {response.status}"
                        
        except asyncio.TimeoutError:
            result.error_message = "è¯·æ±‚è¶…æ—¶"
            result.capture_duration = time.time() - start_time
        except Exception as e:
            result.error_message = f"æŠ“å–å¤±è´¥: {str(e)}"
            result.capture_duration = time.time() - start_time
            self.logger.debug(f"é¡µé¢å†…å®¹æŠ“å–å¤±è´¥: {url} - {e}")
        
        return result
    
    async def get_capture_statistics(self) -> Dict[str, Any]:
        """è·å–æŠ“å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_captured': self.captured_count,
            'total_failed': self.failed_count,
            'success_rate': self.captured_count / (self.captured_count + self.failed_count) if (self.captured_count + self.failed_count) > 0 else 0
        }