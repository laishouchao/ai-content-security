# AIå†…å®¹å®‰å…¨ç›‘æ§ç³»ç»Ÿ - é¡¹ç›®åˆ†æä¸ä¼˜åŒ–è§„åˆ’

## é¡¹ç›®ä¼˜åŒ–ç›®æ ‡ä¸æ ¸å¿ƒè§„åˆ’

### ğŸ¯ æ ¸å¿ƒç›®æ ‡
æœ¬æ¬¡ä¼˜åŒ–è§„åˆ’æ—¨åœ¨å°†ç°æœ‰çš„AIå†…å®¹å®‰å…¨ç›‘æ§ç³»ç»Ÿä»**åŸå‹é˜¶æ®µ**æå‡è‡³**ç”Ÿäº§çº§ä¼ä¸šåº”ç”¨**ï¼Œå…·ä½“ç›®æ ‡åŒ…æ‹¬ï¼š

1. **æŠ€æœ¯æ¶æ„å‡çº§** - ä»å•ä½“åº”ç”¨å‘å¾®æœåŠ¡æ¶æ„æ¼”è¿›
2. **æ€§èƒ½å¤§å¹…æå‡** - æ”¯æŒå¤§è§„æ¨¡å¹¶å‘æ‰«æï¼Œå“åº”é€Ÿåº¦æå‡3-5å€
3. **åŠŸèƒ½æ·±åº¦æ‹“å±•** - ä»åŸºç¡€æ‰«æå‘æ™ºèƒ½åˆ†æå¹³å°è½¬å‹
4. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–** - ä»åŠŸèƒ½å¯¼å‘å‘ç”¨æˆ·ä½“éªŒå¯¼å‘è½¬å˜
5. **ä¼ä¸šçº§èƒ½åŠ›** - æ·»åŠ å¤šç§Ÿæˆ·ã€æƒé™ç®¡ç†ã€åˆè§„æŠ¥å‘Šç­‰ä¼ä¸šåŠŸèƒ½

### ğŸ“‹ å·¥ä½œèŒƒå›´ç•Œå®š

#### ä»£ç ä¼˜åŒ–èŒƒå›´
```mermaid
mindmap
  root((ä»£ç ä¼˜åŒ–))
    å‰ç«¯é‡æ„
      ç»„ä»¶åŒ–æ¶æ„
      çŠ¶æ€ç®¡ç†ä¼˜åŒ–
      æ€§èƒ½ä¼˜åŒ–
      ç”¨æˆ·ä½“éªŒæå‡
    åç«¯é‡æ„
      APIå±‚é‡æ„
      ä¸šåŠ¡é€»è¾‘ä¼˜åŒ–
      æ•°æ®å±‚ä¼˜åŒ–
      å®‰å…¨æ€§å¢å¼º
    åŸºç¡€è®¾æ–½
      æ•°æ®åº“ä¼˜åŒ–
      ç¼“å­˜ç­–ç•¥
      éƒ¨ç½²æ¶æ„
      ç›‘æ§å‘Šè­¦
```

#### åŠŸèƒ½æ‹“å±•èŒƒå›´
- **æ ¸å¿ƒæ‰«æå¼•æ“å¢å¼º** - æå‡æ‰«æç²¾åº¦å’Œæ•ˆç‡
- **AIåˆ†æèƒ½åŠ›æ‰©å±•** - å¤šæ¨¡å‹æ”¯æŒã€æœ¬åœ°åŒ–éƒ¨ç½²
- **ä¼ä¸šçº§ç®¡ç†åŠŸèƒ½** - å¤šç§Ÿæˆ·ã€è§’è‰²æƒé™ã€å®¡è®¡æ—¥å¿—
- **è‡ªåŠ¨åŒ–è¿è¥** - å®šæ—¶ä»»åŠ¡ã€æ™ºèƒ½å‘Šè­¦ã€è‡ªåŠ¨æŠ¥å‘Š
- **ç¬¬ä¸‰æ–¹é›†æˆ** - APIå¼€æ”¾ã€Webhooké€šçŸ¥ã€æ•°æ®åŒæ­¥

### ğŸš€ é¢„æœŸæˆæœé‡åŒ–

| ä¼˜åŒ–ç»´åº¦ | ç°çŠ¶æŒ‡æ ‡ | ç›®æ ‡æŒ‡æ ‡ | æå‡å¹…åº¦ |
|---------|---------|---------|----------|
| å“åº”é€Ÿåº¦ | APIå“åº” 500ms+ | < 200ms (P95) | 60%+ |
| å¹¶å‘å¤„ç† | æ”¯æŒ50ä¸ªä»»åŠ¡ | æ”¯æŒ1000+ä»»åŠ¡ | 20å€ |
| æ‰«ææ•ˆç‡ | å•åŸŸå 30åˆ†é’Ÿ+ | < 10åˆ†é’Ÿ | 70%+ |
| å‡†ç¡®ç‡ | AIè¯†åˆ« 85% | > 95% | 10%+ |
| å¯ç”¨æ€§ | 95% | 99.9% SLA | 4.9%+ |
| ç”¨æˆ·ä½“éªŒ | åŸºç¡€åŠŸèƒ½ | ä¼ä¸šçº§UX | è´¨çš„é£è·ƒ |

---

## 1. é¡¹ç›®ç°çŠ¶åˆ†æ

### 1.1 æŠ€æœ¯æ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "å‰ç«¯å±‚ (Vue.js 3)"
        A[Dashboard] --> B[Task Management]
        A --> C[Domain Library] 
        A --> D[Settings Panel]
        B --> E[Task Creation]
        B --> F[Task Monitoring]
    end
    
    subgraph "APIç½‘å…³å±‚ (FastAPI)"
        G[Authentication] --> H[Task API]
        G --> I[Config API]
        G --> J[Reports API]
        G --> K[WebSocket API]
    end
    
    subgraph "ä¸šåŠ¡é€»è¾‘å±‚"
        L[Scan Executor] --> M[AI Analysis Engine]
        L --> N[Content Capture Engine]
        L --> O[Link Crawler Engine]
        L --> P[Subdomain Discovery Engine]
        L --> Q[Third Party Identifier]
    end
    
    subgraph "ä»»åŠ¡è°ƒåº¦å±‚ (Celery)"
        R[Task Queue] --> S[Scan Workers]
        R --> T[Analysis Workers]
        R --> U[Capture Workers]
    end
    
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        V[PostgreSQL] --> W[Task Records]
        V --> X[User Data]
        V --> Y[Scan Results]
        Z[Redis] --> AA[Cache & Sessions]
        Z --> BB[Task Status]
    end
    
    A --> G
    G --> L
    L --> R
    R --> V
    R --> Z
```

### 1.2 æ ¸å¿ƒæ¨¡å—åˆ†æ

#### åç«¯æ¨¡å—ç»“æ„
- **APIå±‚**: 7ä¸ªä¸»è¦è·¯ç”±æ¨¡å— (auth, tasks, config, reports, admin, websocket, domains)
- **æ ¸å¿ƒå¼•æ“**: 5ä¸ªä¸“ä¸šæ‰«æå¼•æ“
- **æ•°æ®æ¨¡å‹**: å®Œæ•´çš„ç”¨æˆ·ã€ä»»åŠ¡ã€ç»“æœæ•°æ®æ¨¡å‹
- **ä»»åŠ¡ç³»ç»Ÿ**: Celeryå¼‚æ­¥ä»»åŠ¡å¤„ç†
- **å®æ—¶é€šä¿¡**: WebSocketç›‘æ§ç³»ç»Ÿ

#### å‰ç«¯æ¨¡å—ç»“æ„
- **UIæ¡†æ¶**: Vue 3 + TypeScript + Element Plus
- **çŠ¶æ€ç®¡ç†**: PiniaçŠ¶æ€ç®¡ç†
- **è·¯ç”±ç³»ç»Ÿ**: Vue Routeré…ç½®
- **å›¾è¡¨ç»„ä»¶**: EChartså¯è§†åŒ–
- **APIé›†æˆ**: Axios HTTPå®¢æˆ·ç«¯

### 1.3 æŠ€æœ¯æ ˆè¯„ä¼°

#### ä¼˜åŠ¿æŠ€æœ¯é€‰å‹
âœ… **FastAPI**: ç°ä»£Python Webæ¡†æ¶ï¼Œè‡ªåŠ¨APIæ–‡æ¡£ï¼Œç±»å‹æç¤ºæ”¯æŒ  
âœ… **Vue 3 + TypeScript**: å“åº”å¼å‰ç«¯æ¡†æ¶ï¼Œç±»å‹å®‰å…¨  
âœ… **PostgreSQL + Redis**: å¯é çš„å…³ç³»å‹æ•°æ®åº“ + é«˜æ€§èƒ½ç¼“å­˜  
âœ… **Celery**: æˆç†Ÿçš„åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—  
âœ… **Playwright**: ç°ä»£æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·  

#### ä¾èµ–åˆ†æ
- **ç”Ÿäº§ä¾èµ–**: 27ä¸ªæ ¸å¿ƒåŒ…ï¼Œç‰ˆæœ¬ç›¸å¯¹è¾ƒæ–°
- **å¼€å‘ä¾èµ–**: åŒ…å«å®Œæ•´çš„æµ‹è¯•ã€æ ¼å¼åŒ–å·¥å…·é“¾
- **å®‰å…¨æ€§**: ä½¿ç”¨äº†åŠ å¯†åº“ã€è®¤è¯åº“ç­‰å®‰å…¨ç»„ä»¶

## 2. ä»£ç è´¨é‡è¯„ä¼°

### 2.1 æ¶æ„è®¾è®¡è´¨é‡

#### ä¼˜ç§€è®¾è®¡æ¨¡å¼
- **åˆ†å±‚æ¶æ„**: API â†’ ä¸šåŠ¡é€»è¾‘ â†’ æ•°æ®è®¿é—®å±‚æ¸…æ™°åˆ†ç¦»
- **å¼‚æ­¥å¤„ç†**: åˆç†ä½¿ç”¨async/awaitå¤„ç†I/Oå¯†é›†ä»»åŠ¡  
- **ä¾èµ–æ³¨å…¥**: FastAPIçš„ä¾èµ–æ³¨å…¥ç³»ç»Ÿä½¿ç”¨å¾—å½“
- **äº‹ä»¶é©±åŠ¨**: WebSocketå®ç°å®æ—¶ç›‘æ§åŠŸèƒ½

#### éœ€è¦æ”¹è¿›çš„è®¾è®¡
- **å•ä¸€èŒè´£åŸåˆ™**: éƒ¨åˆ†å¼•æ“ç±»åŠŸèƒ½è¿‡äºé›†ä¸­
- **é…ç½®ç®¡ç†**: ç¡¬ç¼–ç é…ç½®è¾ƒå¤šï¼Œç¼ºå°‘ç¯å¢ƒéš”ç¦»
- **é”™è¯¯å¤„ç†**: å¼‚å¸¸å¤„ç†ä¸å¤Ÿç»Ÿä¸€å’Œå®Œå–„

### 2.2 ä»£ç å®ç°è´¨é‡

#### è‰¯å¥½å®è·µ
- **ç±»å‹æç¤º**: åç«¯å¹¿æ³›ä½¿ç”¨ç±»å‹æ³¨è§£
- **æ–‡æ¡£å­—ç¬¦ä¸²**: å…³é”®ç±»å’Œæ–¹æ³•æœ‰è¾ƒå¥½çš„æ–‡æ¡£
- **æ—¥å¿—ç³»ç»Ÿ**: ç»“æ„åŒ–æ—¥å¿—è®°å½•
- **æ•°æ®éªŒè¯**: Pydanticæ¨¡å‹éªŒè¯

#### æŠ€æœ¯å€ºåŠ¡åˆ†æ

**é«˜ä¼˜å…ˆçº§æŠ€æœ¯å€ºåŠ¡**
```mermaid
graph LR
    A[æŠ€æœ¯å€ºåŠ¡] --> B[é«˜ä¼˜å…ˆçº§]
    A --> C[ä¸­ä¼˜å…ˆçº§]
    A --> D[ä½ä¼˜å…ˆçº§]
    
    B --> B1[æ•°æ®åº“N+1æŸ¥è¯¢]
    B --> B2[å†…å­˜æ³„æ¼é£é™©]
    B --> B3[å¹¶å‘æ§åˆ¶ç¼ºå¤±]
    B --> B4[é”™è¯¯å¤„ç†ä¸ç»Ÿä¸€]
    
    C --> C1[ç¼“å­˜ç­–ç•¥ç¼ºå¤±]
    C --> C2[é…ç½®ç®¡ç†æ•£ä¹±]
    C --> C3[ä»£ç å¤ç”¨åº¦ä½]
    C --> C4[æ—¥å¿—çº§åˆ«ä¸åˆç†]
    
    D --> D1[ä»£ç æ³¨é‡Šä¸è¶³]
    D --> D2[å˜é‡å‘½åä¸è§„èŒƒ]
    D --> D3[æ–‡ä»¶ç»„ç»‡å¯ä¼˜åŒ–]
```

**å…·ä½“é—®é¢˜æ¸…å•**

1. **æ•°æ®åº“æ€§èƒ½é—®é¢˜** (ğŸ”´ ç´§æ€¥)
   - `ScanTaskExecutor._save_scan_results()` å­˜åœ¨æ‰¹é‡æ’å…¥ç¼ºå¤±
   - `TaskList.vue` åˆ—è¡¨æŸ¥è¯¢ç¼ºå°‘åˆ†é¡µä¼˜åŒ–
   - å­åŸŸåè®°å½•æŸ¥è¯¢æœªä½¿ç”¨ç´¢å¼•

2. **å†…å­˜ç®¡ç†é—®é¢˜** (ğŸ”´ ç´§æ€¥)
   - `ContentCaptureEngine` æˆªå›¾æ–‡ä»¶æœªåŠæ—¶æ¸…ç†
   - `LinkCrawlerEngine` çˆ±å–ç»“æœç´¯ç§¯å ç”¨å†…å­˜
   - å‰ç«¯å¤§æ•°æ®åˆ—è¡¨æœªè™šæ‹ŸåŒ–

3. **å¹¶å‘å®‰å…¨é—®é¢˜** (ğŸŸŸ é‡è¦)
   - Redisæ“ä½œç¼ºå°‘åŸå­æ€§ä¿è¯
   - ä»»åŠ¡çŠ¶æ€æ›´æ–°ç«æ€æ¡ä»¶
   - WebSocketè¿æ¥ç®¡ç†ç¼ºå°‘é”æœºåˆ¶

4. **é”™è¯¯å¤„ç†ä¸ç»Ÿä¸€** (ğŸŸŸ é‡è¦)
   - AI APIè°ƒç”¨å¤±è´¥é‡è¯•æœºåˆ¶ä¸å®Œå–„
   - æ•°æ®åº“è¿æ¥å¼‚å¸¸å¤„ç†ç¼ºå¤±
   - å‰ç«¯é”™è¯¯è¾¹ç•Œå¤„ç†ä¸å……åˆ†

#### ä»£ç è´¨é‡æ”¹è¿›è®¡åˆ’

**Phase 1: ç´§æ€¥ä¿®å¤** (1-2å‘¨)
```python
# 1. æ•°æ®åº“æ‰¹é‡æ“ä½œä¼˜åŒ–
async def batch_insert_subdomains(self, subdomains: List[SubdomainResult]):
    """æ‰¹é‡æ’å…¥å­åŸŸåè®°å½•"""
    batch_size = 1000
    for i in range(0, len(subdomains), batch_size):
        batch = subdomains[i:i + batch_size]
        records = [SubdomainRecord(**subdomain.dict()) for subdomain in batch]
        await self.db.execute(insert(SubdomainRecord).values([r.dict() for r in records]))
        
# 2. å†…å­˜ç®¡ç†ä¼˜åŒ–  
async def capture_content_with_cleanup(self, url: str) -> ContentResult:
    """RAIIæ¨¡å¼çš„å†…å®¹æ•è·"""
    temp_files = []
    try:
        result = await self._do_capture(url)
        temp_files.extend(result.temp_files)
        return result
    finally:
        # è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in temp_files:
            Path(temp_file).unlink(missing_ok=True)
            
# 3. å¹¶å‘å®‰å…¨ä¼˜åŒ–
from redis.lock import Lock

async def update_task_status_safe(self, task_id: str, status: TaskStatus):
    """çº¿ç¨‹å®‰å…¨çš„ä»»åŠ¡çŠ¶æ€æ›´æ–°"""
    lock_key = f"task_update_lock:{task_id}"
    async with Lock(self.redis, lock_key, timeout=30):
        await self._update_task_status(task_id, status)
```

**Phase 2: ç³»ç»Ÿæ€§é‡æ„** (3-4å‘¨)
```python
# ä¾èµ–æ³¨å…¥å®¹å™¨è®¾è®¡
from dependency_injector import containers, providers

class ApplicationContainer(containers.DeclarativeContainer):
    # Configuration
    config = providers.Configuration()
    
    # Infrastructure
    database = providers.Singleton(
        AsyncDatabase,
        url=config.database.url
    )
    
    redis = providers.Singleton(
        AsyncRedis,
        url=config.redis.url
    )
    
    # Services
    task_service = providers.Factory(
        TaskService,
        db=database,
        cache=redis
    )
    
    scan_executor = providers.Factory(
        ScanTaskExecutor,
        task_service=task_service,
        engines=providers.Dict(
            subdomain=providers.Factory(SubdomainDiscoveryEngine),
            crawler=providers.Factory(LinkCrawlerEngine),
            ai_analysis=providers.Factory(AIAnalysisEngine)
        )
    )
```

### 2.3 æµ‹è¯•è¦†ç›–ç‡

#### ç°æœ‰æµ‹è¯•
- **APIæµ‹è¯•**: åŸºç¡€çš„APIç«¯ç‚¹æµ‹è¯•
- **é›†æˆæµ‹è¯•**: éƒ¨åˆ†ä¸šåŠ¡æµç¨‹æµ‹è¯•
- **æ€§èƒ½æµ‹è¯•**: ç®€å•çš„æ€§èƒ½åŸºå‡†æµ‹è¯•

#### æµ‹è¯•ç¼ºå£
- **å•å…ƒæµ‹è¯•**: å¼•æ“æ¨¡å—å•å…ƒæµ‹è¯•ä¸è¶³
- **å‰ç«¯æµ‹è¯•**: ç¼ºå°‘Vueç»„ä»¶æµ‹è¯•
- **ç«¯åˆ°ç«¯æµ‹è¯•**: ç¼ºå°‘å®Œæ•´çš„E2Eæµ‹è¯•

## 3. åŠŸèƒ½åˆ†æä¸æ‹“å±•è§„åˆ’

### 3.1 ç°æœ‰æ ¸å¿ƒåŠŸèƒ½

#### æ‰«æå¼•æ“åŠŸèƒ½ - å¢å¼ºç‰ˆåŠ¨æ€å‘ç°æµç¨‹

```mermaid
flowchart LR
    A[Target Domain] --> B[Initial Subdomain Discovery]
    B --> C[Iterative Link Crawling]
    C --> D[Dynamic Subdomain Extraction]
    D --> E[Domain Classification]
    E --> F{Is Target Subdomain?}
    F -->|Yes| G[Add to Subdomain Pool]
    F -->|No| H[Third Party Analysis]
    G --> I[Continue Crawling]
    H --> J[1-Layer Access Testing]
    J --> K[Content Capture & Screenshot]
    K --> L[AI Domain Classification]
    L --> M[Store in Domain Library]
    I --> C
    D --> F
```

**æ–°çš„æ‰«æå¼•æ“æµç¨‹è®¾è®¡**

1. **åˆå§‹å­åŸŸåå‘ç°** (Initial Subdomain Discovery)
   - **DNSæŸ¥è¯¢**: é€šè¿‡å„ç§ DNS è®°å½•ç±»å‹æŸ¥è¯¢ (A, AAAA, CNAME, MX, NS, TXT)
   - **è¯ä¹¦é€æ˜åº¦**: Certificate Transparency æ—¥å¿—æŸ¥è¯¢
   - **æœç´¢å¼•æ“**: Google/Bing/Baidu æœç´¢ç»“æœæå–

2. **è¿­ä»£å¼é“¾æ¥çˆ¬å–** (Iterative Link Crawling)
   - æ”¯æŒ JavaScript æ¸²æŸ“çš„ç½‘é¡µæŠ“å–
   - ä»æ¯ä¸ªé¡µé¢æå–æ‰€æœ‰é“¾æ¥ï¼ˆhref, src, action ç­‰ï¼‰
   - æ™ºèƒ½å»é‡å’Œæ·±åº¦æ§åˆ¶

3. **åŠ¨æ€å­åŸŸåæå–** (Dynamic Subdomain Extraction)
   - ä»çˆ¬å–çš„é“¾æ¥ä¸­æå–æ‰€æœ‰åŸŸå
   - æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡åŸŸåçš„å­åŸŸå
   - æ–°å‘ç°çš„å­åŸŸååŠ å…¥å¾…çˆ¬å–é˜Ÿåˆ—

4. **åŸŸååˆ†ç±»å¤„ç†** (Domain Classification)
   - **ç›®æ ‡å­åŸŸå**: ç»§ç»­è¿­ä»£çˆ¬å–
   - **ç¬¬ä¸‰æ–¹åŸŸå**: è¿›å…¥ç¬¬ä¸‰æ–¹åˆ†ææµç¨‹

5. **ç¬¬ä¸‰æ–¹åŸŸåæ™ºèƒ½åˆ†æ** (Third Party Analysis)
   - **1å±‚è®¿é—®æµ‹è¯•**: æµ‹è¯•åŸŸåå¯è®¿é—®æ€§
   - **å†…å®¹æŠ“å–**: é¡µé¢å†…å®¹å’Œæˆªå›¾è·å–
   - **AIæ™ºèƒ½åˆ†ç±»**: ä½¿ç”¨å›ºå®šåˆ†ç±»æç¤ºè¯è¿›è¡ŒAIåˆ†æ
   - **å…³è”ä¿¡æ¯å­˜å‚¨**: è®°å½•åœ¨å“ªäº›é¡µé¢å‘ç°äº†è¯¥åŸŸå

**æ ¸å¿ƒå®ç°ä»£ç **

```python
# åŠ¨æ€å­åŸŸåå‘ç°å¼•æ“
class EnhancedSubdomainDiscovery:
    def __init__(self, target_domain: str):
        self.target_domain = target_domain
        self.discovered_subdomains = set()
        self.third_party_domains = set()
        self.domain_sources = {}  # è®°å½•åŸŸåæ¥æºé¡µé¢
        
    async def extract_domains_from_links(self, links: List[str], source_url: str) -> Tuple[List[str], List[str]]:
        """ä»é“¾æ¥ä¸­æå–åŸŸåå¹¶åˆ†ç±»"""
        new_subdomains = []
        third_party_domains = []
        
        for link in links:
            try:
                parsed = urlparse(link)
                if not parsed.netloc:
                    continue
                    
                domain = parsed.netloc.lower()
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡åŸŸåçš„å­åŸŸå
                if self._is_target_subdomain(domain):
                    if domain not in self.discovered_subdomains:
                        new_subdomains.append(domain)
                        self.discovered_subdomains.add(domain)
                        self._record_domain_source(domain, source_url)
                else:
                    # ç¬¬ä¸‰æ–¹åŸŸå
                    if domain not in self.third_party_domains:
                        third_party_domains.append(domain)
                        self.third_party_domains.add(domain)
                        self._record_domain_source(domain, source_url)
                        
            except Exception as e:
                logger.warning(f"è§£æé“¾æ¥å¤±è´¥: {link}, é”™è¯¯: {e}")
                
        return new_subdomains, third_party_domains
    
    def _is_target_subdomain(self, domain: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡åŸŸåçš„å­åŸŸå"""
        if domain == self.target_domain:
            return True
        if domain.endswith(f'.{self.target_domain}'):
            return True
        return False
    
    def _record_domain_source(self, domain: str, source_url: str):
        """è®°å½•åŸŸåæ¥æºé¡µé¢"""
        if domain not in self.domain_sources:
            self.domain_sources[domain] = []
        self.domain_sources[domain].append(source_url)

# ç¬¬ä¸‰æ–¹åŸŸåæ™ºèƒ½åˆ†æå¼•æ“
class ThirdPartyDomainAnalyzer:
    def __init__(self, ai_client: AIAnalysisEngine):
        self.ai_client = ai_client
        self.classification_prompt = self._build_classification_prompt()
        
    async def analyze_domain(self, domain: str, source_urls: List[str]) -> ThirdPartyDomainResult:
        """å¯¹ç¬¬ä¸‰æ–¹åŸŸåè¿›è¡Œå…¨é¢åˆ†æ"""
        result = ThirdPartyDomainResult(
            domain=domain,
            source_urls=source_urls,
            discovered_at=datetime.utcnow()
        )
        
        try:
            # 1å±‚è®¿é—®æµ‹è¯•
            access_result = await self._test_domain_access(domain)
            result.is_accessible = access_result['accessible']
            result.response_code = access_result['status_code']
            result.response_time = access_result['response_time']
            
            if result.is_accessible:
                # å†…å®¹æŠ“å–å’Œæˆªå›¾
                content_result = await self._capture_domain_content(domain)
                result.page_title = content_result['title']
                result.page_content = content_result['content']
                result.screenshot_path = content_result['screenshot']
                
                # AIæ™ºèƒ½åˆ†ç±»
                classification = await self._classify_domain_with_ai(
                    domain, content_result
                )
                result.domain_type = classification['category']
                result.risk_level = classification['risk_level']
                result.confidence_score = classification['confidence']
                result.description = classification['description']
                result.tags = classification['tags']
                
        except Exception as e:
            logger.error(f"åˆ†æåŸŸå {domain} å¤±è´¥: {e}")
            result.error_message = str(e)
            
        return result
    
    async def _test_domain_access(self, domain: str) -> Dict[str, Any]:
        """æµ‹è¯•åŸŸåå¯è®¿é—®æ€§"""
        start_time = time.time()
        
        # å°è¯• HTTPS å’Œ HTTP
        for protocol in ['https', 'http']:
            url = f"{protocol}://{domain}"
            try:
                async with aiohttp.ClientSession(
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as session:
                    async with session.get(url) as response:
                        return {
                            'accessible': True,
                            'status_code': response.status,
                            'response_time': time.time() - start_time,
                            'final_url': str(response.url),
                            'protocol': protocol
                        }
            except Exception as e:
                logger.debug(f"è®¿é—® {url} å¤±è´¥: {e}")
                continue
                
        return {
            'accessible': False,
            'status_code': None,
            'response_time': time.time() - start_time,
            'error': 'æ— æ³•è®¿é—®'
        }
    
    async def _capture_domain_content(self, domain: str) -> Dict[str, Any]:
        """æŠ“å–åŸŸåå†…å®¹å’Œæˆªå›¾"""
        url = f"https://{domain}"
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            try:
                page = await browser.new_page()
                await page.set_viewport_size({"width": 1280, "height": 720})
                await page.goto(url, wait_until='networkidle', timeout=15000)
                
                title = await page.title()
                content = await page.content()
                
                screenshot_path = f"screenshots/third_party/{domain}_{int(time.time())}.png"
                await page.screenshot(path=screenshot_path, full_page=True)
                
                return {
                    'title': title,
                    'content': content,
                    'screenshot': screenshot_path,
                    'url': url
                }
            finally:
                await browser.close()
    
    async def _classify_domain_with_ai(self, domain: str, content_data: Dict) -> Dict[str, Any]:
        """ä½¿ç”¨AIå¯¹åŸŸåè¿›è¡Œæ™ºèƒ½åˆ†ç±»"""
        
        # å›ºå®šåˆ†ç±»æç¤ºè¯
        analysis_prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç¬¬ä¸‰æ–¹åŸŸåçš„ç±»å‹å’Œé£é™©ç­‰çº§ï¼š

åŸŸå: {domain}
é¡µé¢æ ‡é¢˜: {content_data['title']}
é¡µé¢URL: {content_data['url']}

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
  "category": "åŸŸåç±»å‹ï¼ˆcdn/analytics/advertising/social/api/payment/security/maps/unknownï¼‰",
  "risk_level": "é£é™©ç­‰çº§ï¼ˆlow/medium/high/criticalï¼‰",
  "confidence": "ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰",
  "description": "è¯¦ç»†æè¿°",
  "tags": ["æ ‡ç­¾åˆ—è¡¨"],
  "business_purpose": "ä¸šåŠ¡ç”¨é€”",
  "potential_risks": ["æ½œåœ¨é£é™©"],
  "recommendations": ["å»ºè®®æªæ–½"]
}}
        """
        
        try:
            # è¯»å–æˆªå›¾æ–‡ä»¶
            with open(content_data['screenshot'], 'rb') as f:
                screenshot_data = base64.b64encode(f.read()).decode()
            
            # è°ƒç”¨AIåˆ†æ
            ai_result = await self.ai_client.analyze_content(
                prompt=analysis_prompt,
                image_data=screenshot_data
            )
            
            # è§£æAIè¿”å›çš„JSON
            classification = json.loads(ai_result.get('choices', [{}])[0].get('message', {}).get('content', '{}'))
            
            return {
                'category': classification.get('category', 'unknown'),
                'risk_level': classification.get('risk_level', 'low'),
                'confidence': float(classification.get('confidence', 0.0)),
                'description': classification.get('description', ''),
                'tags': classification.get('tags', []),
                'business_purpose': classification.get('business_purpose', ''),
                'potential_risks': classification.get('potential_risks', []),
                'recommendations': classification.get('recommendations', [])
            }
            
        except Exception as e:
            logger.error(f"AIåˆ†ç±»å¤±è´¥: {e}")
            return {
                'category': 'unknown',
                'risk_level': 'low',
                'confidence': 0.0,
                'description': 'AIåˆ†æå¤±è´¥',
                'tags': [],
                'business_purpose': '',
                'potential_risks': [],
                'recommendations': []
            }

# æ•°æ®æ¨¡å‹å®šä¹‰
class ThirdPartyDomainResult:
    def __init__(self, domain: str, source_urls: List[str], discovered_at: datetime):
        self.domain = domain
        self.source_urls = source_urls  # å‘ç°è¯¥åŸŸåçš„æºé¡µé¢
        self.discovered_at = discovered_at
        
        # è®¿é—®æµ‹è¯•ç»“æœ
        self.is_accessible = False
        self.response_code = None
        self.response_time = 0.0
        self.final_url = ""
        
        # å†…å®¹ä¿¡æ¯
        self.page_title = ""
        self.page_content = ""
        self.screenshot_path = ""
        
        # AIåˆ†ç±»ç»“æœ
        self.domain_type = "unknown"
        self.risk_level = "low"
        self.confidence_score = 0.0
        self.description = ""
        self.tags = []
        self.business_purpose = ""
        self.potential_risks = []
        self.recommendations = []
        
        # é”™è¯¯ä¿¡æ¯
        self.error_message = ""

# æ•´åˆåçš„æ‰«ææ‰§è¡Œå™¨
class EnhancedScanExecutor:
    def __init__(self, task_id: str, user_id: str):
        self.task_id = task_id
        self.user_id = user_id
        self.subdomain_discovery = EnhancedSubdomainDiscovery("")
        self.third_party_analyzer = ThirdPartyDomainAnalyzer(AIAnalysisEngine())
        
    async def execute_enhanced_scan(self, target_domain: str, config: Dict[str, Any]):
        """æ‰§è¡Œå¢å¼ºç‰ˆæ‰«æ"""
        self.subdomain_discovery.target_domain = target_domain
        
        # é˜¶æ®µ1: åˆå§‹å­åŸŸåå‘ç°
        initial_subdomains = await self._initial_subdomain_discovery(target_domain, config)
        logger.info(f"åˆå§‹å‘ç°å­åŸŸå: {len(initial_subdomains)} ä¸ª")
        
        # é˜¶æ®µ2: è¿­ä»£å¼ç½‘é¡µçˆ¬å–å’ŒåŠ¨æ€å‘ç°
        crawl_queue = list(initial_subdomains)
        processed_domains = set()
        iteration = 0
        max_iterations = config.get('max_iterations', 10)
        
        while crawl_queue and iteration < max_iterations:
            iteration += 1
            logger.info(f"å¼€å§‹ç¬¬ {iteration} è½®çˆ¬å–ï¼Œå¾…å¤„ç†åŸŸå: {len(crawl_queue)}")
            
            current_batch = crawl_queue.copy()
            crawl_queue.clear()
            
            for subdomain in current_batch:
                if subdomain in processed_domains:
                    continue
                    
                processed_domains.add(subdomain)
                
                # çˆ¬å–å­åŸŸåé¡µé¢
                crawl_result = await self._crawl_subdomain_pages(subdomain, config)
                
                # ä»æ¯ä¸ªé¡µé¢æå–æ–°åŸŸå
                for page_data in crawl_result.pages:
                    new_subdomains, third_party_domains = await self.subdomain_discovery.extract_domains_from_links(
                        page_data.links, page_data.url
                    )
                    
                    # æ·»åŠ æ–°å‘ç°çš„å­åŸŸååˆ°çˆ¬å–é˜Ÿåˆ—
                    for new_subdomain in new_subdomains:
                        if new_subdomain not in processed_domains:
                            crawl_queue.append(new_subdomain)
                            logger.info(f"å‘ç°æ–°å­åŸŸå: {new_subdomain}")
                    
                    # å¤„ç†ç¬¬ä¸‰æ–¹åŸŸå
                    if third_party_domains:
                        await self._process_third_party_domains(third_party_domains)
                    
        logger.info(f"æ‰«æå®Œæˆï¼Œæœ€ç»ˆå‘ç°å­åŸŸå: {len(self.subdomain_discovery.discovered_subdomains)} ä¸ª")
        logger.info(f"å‘ç°ç¬¬ä¸‰æ–¹åŸŸå: {len(self.subdomain_discovery.third_party_domains)} ä¸ª")
        
    async def _process_third_party_domains(self, domains: List[str]):
        """å¤„ç†ç¬¬ä¸‰æ–¹åŸŸå"""
        for domain in domains:
            try:
                source_urls = self.subdomain_discovery.domain_sources.get(domain, [])
                analysis_result = await self.third_party_analyzer.analyze_domain(domain, source_urls)
                
                # å­˜å‚¨åˆ°æ•°æ®åº“çš„åŸŸååº“
                await self._save_to_domain_library(analysis_result)
                logger.info(f"ç¬¬ä¸‰æ–¹åŸŸå {domain} åˆ†æå®Œæˆï¼Œåˆ†ç±»: {analysis_result.domain_type}")
                
            except Exception as e:
                logger.error(f"å¤„ç†ç¬¬ä¸‰æ–¹åŸŸå {domain} å¤±è´¥: {e}")
    
    async def _save_to_domain_library(self, result: ThirdPartyDomainResult):
        """ä¿å­˜åˆ°åŸŸååº“"""
        # ä¿å­˜åˆ°æ•°æ®åº“çš„å…·ä½“å®ç°
        domain_record = ThirdPartyDomain(
            task_id=self.task_id,
            domain=result.domain,
            domain_type=result.domain_type,
            risk_level=result.risk_level,
            is_accessible=result.is_accessible,
            response_code=result.response_code,
            page_title=result.page_title,
            screenshot_path=result.screenshot_path,
            confidence_score=result.confidence_score,
            description=result.description,
            source_urls=result.source_urls,  # JSONå­—æ®µå­˜å‚¨æºé¡µé¢åˆ—è¡¨
            ai_analysis_result={
                'tags': result.tags,
                'business_purpose': result.business_purpose,
                'potential_risks': result.potential_risks,
                'recommendations': result.recommendations
            }
        )
        # ä¿å­˜åˆ°æ•°æ®åº“...
```

#### ç›‘æ§ä¸ç®¡ç†åŠŸèƒ½
- **å®æ—¶ç›‘æ§**: WebSocketä»»åŠ¡è¿›åº¦æ¨é€
- **ä»»åŠ¡ç®¡ç†**: åˆ›å»ºã€åœæ­¢ã€é‡è¯•ã€åˆ é™¤ä»»åŠ¡
- **ç»“æœåˆ†æ**: è¿è§„ç»Ÿè®¡ã€é£é™©è¯„ä¼°ã€æŠ¥å‘Šç”Ÿæˆ
- **ç”¨æˆ·ç³»ç»Ÿ**: è®¤è¯ã€æƒé™ã€é…ç½®ç®¡ç†

### 3.2 åŠŸèƒ½æ‹“å±•è·¯çº¿å›¾

#### 3.2.1 é«˜çº§æ‰«æåŠŸèƒ½è¯¦ç»†è®¾è®¡

**å®šæ—¶ç›‘æ§ç³»ç»Ÿ**
```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant S as è°ƒåº¦å™¨
    participant T as ä»»åŠ¡å¼•æ“
    participant N as é€šçŸ¥ç³»ç»Ÿ
    
    U->>S: åˆ›å»ºå®šæ—¶ä»»åŠ¡(Cronè¡¨è¾¾å¼)
    S->>S: è§£æCronï¼Œè®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
    
    loop æ¯æ¬¡å®šæ—¶æ‰§è¡Œ
        S->>T: è§¦å‘æ‰«æä»»åŠ¡
        T->>T: æ‰§è¡ŒåŸŸåæ‰«æ
        T->>T: å¯¹æ¯”å†å²ç»“æœ(å˜åŒ–æ£€æµ‹)
        
        alt å‘ç°æ–°è¿è§„
            T->>N: å‘é€ç´§æ€¥é€šçŸ¥
            T->>U: æ¨é€å®æ—¶å‘Šè­¦
        end
        
        T->>S: æ›´æ–°ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
    end
```

**æ·±åº¦å†…å®¹åˆ†ææ‰©å±•**

1. **å¤šåª’ä½“å†…å®¹æ”¯æŒ**
   ```python
   # PDFæ–‡æ¡£åˆ†æ
   class PDFAnalyzer:
       async def extract_text_and_images(self, pdf_url: str) -> PDFAnalysisResult:
           # ä½¿ç”¨PyMuPDFæå–æ–‡æœ¬å’Œå›¾ç‰‡
           # åˆ†åˆ«è¿›è¡ŒAIåˆ†æ
           pass
           
   # è§†é¢‘å†…å®¹åˆ†æ  
   class VideoAnalyzer:
       async def analyze_video_content(self, video_url: str) -> VideoAnalysisResult:
           # å…³é”®å¸§æå– + éŸ³é¢‘è½¬æ–‡æœ¬ + AIåˆ†æ
           pass
   ```

2. **è‡ªå®šä¹‰è§„åˆ™å¼•æ“**
   ```yaml
   # è§„åˆ™å®šä¹‰ç¤ºä¾‹
   custom_rules:
     - name: "é‡‘èæ¬ºè¯ˆæ£€æµ‹"
       type: "text_pattern"
       patterns:
         - "é«˜æ”¶ç›Š.*ä½é£é™©"
         - "ä¿è¯.*æ—¥åˆ©ç‡"
       severity: "high"
       
     - name: "è¿æ³•å¹¿å‘Šæ£€æµ‹"
       type: "ai_classifier" 
       model: "custom_bert_classifier"
       threshold: 0.85
       categories: ["medical_ads", "financial_scam"]
   ```

#### 3.2.2 AIèƒ½åŠ›å¢å¼ºè¯¦ç»†æ–¹æ¡ˆ

**å¤šAIæ¨¡å‹ç»Ÿä¸€æ¥å£è®¾è®¡**
```python
from abc import ABC, abstractmethod
from enum import Enum

class AIProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic" 
    GOOGLE = "google"
    LOCAL = "local"

class BaseAIProvider(ABC):
    @abstractmethod
    async def analyze_content(
        self, 
        prompt: str, 
        content: Union[str, bytes],
        content_type: str
    ) -> AIAnalysisResult:
        pass
        
    @abstractmethod
    async def get_model_info(self) -> ModelInfo:
        pass

class AIProviderFactory:
    _providers = {
        AIProvider.OPENAI: OpenAIProvider,
        AIProvider.ANTHROPIC: AnthropicProvider,
        AIProvider.GOOGLE: GoogleProvider,
        AIProvider.LOCAL: LocalAIProvider
    }
    
    @classmethod
    def create_provider(cls, provider_type: AIProvider, config: dict) -> BaseAIProvider:
        provider_class = cls._providers[provider_type]
        return provider_class(config)

# æ™ºèƒ½è·¯ç”±ç­–ç•¥
class AIRoutingStrategy:
    def __init__(self):
        self.providers = [
            (AIProvider.LOCAL, 0.7),      # 70% ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            (AIProvider.OPENAI, 0.2),     # 20% ä½¿ç”¨OpenAI
            (AIProvider.ANTHROPIC, 0.1)   # 10% ä½¿ç”¨Anthropic
        ]
        
    async def select_provider(self, content_type: str, urgency: str) -> AIProvider:
        # æ ¹æ®å†…å®¹ç±»å‹ã€ç´§æ€¥ç¨‹åº¦ã€æˆæœ¬ç­‰å› ç´ é€‰æ‹©æœ€ä¼˜AIæœåŠ¡
        if urgency == "high" and content_type == "image":
            return AIProvider.OPENAI  # é«˜ç´§æ€¥æƒ…å†µä¼˜å…ˆä½¿ç”¨æœ€å¿«æœ€å‡†çš„æ¨¡å‹
        return self._select_by_load_balancing()
```

**æœ¬åœ°AIæ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆ**
```yaml
# docker-compose.local-ai.yml
version: '3.8'
services:
  local-ai-service:
    image: localai/localai:latest
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models
      - ./config.yaml:/config.yaml
    environment:
      - MODELS_PATH=/models
      - CONFIG_FILE=/config.yaml
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

#### 3.2.3 ä¼ä¸šçº§åŠŸèƒ½è®¾è®¡

**å¤šç§Ÿæˆ·æ¶æ„è®¾è®¡**
```python
# ç»„ç»‡æ¶æ„æ¨¡å‹
class Organization(Base):
    __tablename__ = "organizations"
    
    id = Column(String(36), primary_key=True)
    name = Column(String(255), nullable=False)
    subscription_plan = Column(String(50), nullable=False)  # basic/pro/enterprise
    max_concurrent_scans = Column(Integer, default=10)
    max_monthly_scans = Column(Integer, default=1000)
    
    # åŠŸèƒ½æƒé™æ§åˆ¶
    features_enabled = Column(JSON, default=lambda: {
        "advanced_ai_models": False,
        "custom_rules": False,  
        "api_access": False,
        "white_label": False
    })
    
    users = relationship("User", back_populates="organization")
    teams = relationship("Team", back_populates="organization")

class Team(Base):
    __tablename__ = "teams"
    
    id = Column(String(36), primary_key=True)
    organization_id = Column(String(36), ForeignKey("organizations.id"))
    name = Column(String(255), nullable=False)
    permissions = Column(JSON)  # ç²’åº¦æƒé™æ§åˆ¶
    
    organization = relationship("Organization", back_populates="teams")
    members = relationship("TeamMember", back_populates="team")

# æƒé™æ§åˆ¶è£…é¥°å™¨
from functools import wraps

def require_permission(permission: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(current_user: User, *args, **kwargs):
            if not current_user.has_permission(permission):
                raise HTTPException(status_code=403, detail=f"ç¼ºå°‘æƒé™: {permission}")
            return await func(current_user, *args, **kwargs)
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@app.post("/api/v1/tasks")
@require_permission("task:create")
async def create_scan_task(current_user: User, task_data: CreateTaskRequest):
    pass
```

**APIå¼€æ”¾å¹³å°è®¾è®¡**
```python
# APIå¯†é’¥ç®¡ç†
class APIKey(Base):
    __tablename__ = "api_keys"
    
    id = Column(String(36), primary_key=True)
    organization_id = Column(String(36), ForeignKey("organizations.id"))
    name = Column(String(255), nullable=False)
    key_hash = Column(String(255), nullable=False)  # åŠ å¯†å­˜å‚¨
    permissions = Column(JSON)  # APIæƒé™æ§åˆ¶
    rate_limit = Column(Integer, default=1000)  # æ¯å°æ—¶è¯·æ±‚é™åˆ¶
    
    created_at = Column(DateTime, default=datetime.utcnow)
    last_used = Column(DateTime)
    expires_at = Column(DateTime)  # å¯†é’¥è¿‡æœŸæ—¶é—´
    is_active = Column(Boolean, default=True)

# Webhooké€šçŸ¥ç³»ç»Ÿ
class WebhookEndpoint(Base):
    __tablename__ = "webhook_endpoints"
    
    id = Column(String(36), primary_key=True) 
    organization_id = Column(String(36), ForeignKey("organizations.id"))
    url = Column(String(500), nullable=False)
    secret = Column(String(255))  # ç­¾åå¯†é’¥
    events = Column(JSON)  # è®¢é˜…çš„äº‹ä»¶ç±»å‹
    is_active = Column(Boolean, default=True)
    
    # é‡è¯•ç­–ç•¥
    retry_config = Column(JSON, default=lambda: {
        "max_retries": 3,
        "backoff_factor": 2,
        "timeout_seconds": 30
    })

async def send_webhook_notification(event_type: str, payload: dict, organization_id: str):
    """Webhookäº‹ä»¶é€šçŸ¥"""
    endpoints = await get_active_webhooks(organization_id, event_type)
    
    for endpoint in endpoints:
        await asyncio.create_task(
            deliver_webhook_with_retry(endpoint, payload)
        )
```

#### 3.2.0 å‰ç«¯TODOåŠŸèƒ½å®ç°ä¸æ–°å¢æ¨¡å—è®¾è®¡

**å½“å‰å‰ç«¯åŠŸèƒ½ç¼ºå¤±åˆ†æ**

é€šè¿‡ä»£ç æ‰«æå‘ç°ï¼Œå‰ç«¯å­˜åœ¨å¤§é‡TODOæ ‡è®°å’Œçº¯å‰ç«¯æ•ˆæœï¼Œéœ€è¦å®Œå–„ä¸ºçœŸå®çš„å‰åç«¯äº¤äº’åŠŸèƒ½ï¼š

```mermaid
graph TB
    subgroup["å‰ç«¯å¾…å®Œå–„åŠŸèƒ½"]
    A["ğŸ”§ TODOåŠŸèƒ½"] --> A1["ç³»ç»Ÿé…ç½®ä¿å­˜"]
    A --> A2["é€šçŸ¥é…ç½®æµ‹è¯•"]
    A --> A3["ç”¨æˆ·æ³¨å†ŒAPI"]
    A --> A4["ç³»ç»Ÿä¿¡æ¯åˆ·æ–°"]
    A --> A5["å®‰å…¨é…ç½®é‡ç½®"]
    
    B["ğŸ“‹ ç¼ºå¤±æ¨¡å—"] --> B1["åŸŸåç™½åå•ç®¡ç†"]
    B --> B2["IPé»‘åå•ç®¡ç†"]
    B --> B3["æ‰«æè§„åˆ™æ¨¡æ¿"]
    B --> B4["å®¡è®¡æ—¥å¿—æŸ¥çœ‹"]
    B --> B5["å®šæ—¶ä»»åŠ¡ç®¡ç†"]
    
    C["ğŸ¨ çº¯å‰ç«¯æ•ˆæœ"] --> C1["ç³»ç»ŸçŠ¶æ€ç›‘æ§"]
    C --> C2["æ€§èƒ½æŒ‡æ ‡å›¾è¡¨"]
    C --> C3["å®æ—¶é€šçŸ¥"]
    C --> C4["æ–‡ä»¶å¯¼å‡ºåŠŸèƒ½"]
```

**æ–°å¢å‰ç«¯æ¨¡å—è®¾è®¡**

**1. åŸŸåç™½åå•ç®¡ç†æ¨¡å—**
```vue
<!-- DomainWhitelist.vue -->
<template>
  <div class="domain-whitelist">
    <div class="page-header">
      <h2>åŸŸåç™½åå•</h2>
      <p>ç®¡ç†å—ä¿¡ä»»çš„åŸŸåï¼Œç™½åå•å†…çš„åŸŸåå°†è·³è¿‡å®‰å…¨æ£€æŸ¥</p>
    </div>

    <!-- æ“ä½œåŒºåŸŸ -->
    <el-card class="action-card">
      <el-row :gutter="16">
        <el-col :span="12">
          <el-input
            v-model="newDomain"
            placeholder="è¯·è¾“å…¥åŸŸåï¼Œå¦‚ï¼šexample.com æˆ– *.cdn.com"
            @keyup.enter="addDomain"
          >
            <template #prepend>
              <el-icon><Link /></el-icon>
            </template>
            <template #append>
              <el-button type="primary" @click="addDomain">
                <el-icon><Plus /></el-icon>
                æ·»åŠ 
              </el-button>
            </template>
          </el-input>
        </el-col>
        <el-col :span="12">
          <el-upload
            :before-upload="handleBatchUpload"
            :show-file-list="false"
            accept=".txt,.csv"
          >
            <el-button type="success">
              <el-icon><Upload /></el-icon>
              æ‰¹é‡å¯¼å…¥
            </el-button>
          </el-upload>
          <el-button @click="exportWhitelist">
            <el-icon><Download /></el-icon>
            å¯¼å‡ºåˆ—è¡¨
          </el-button>
        </el-col>
      </el-row>
    </el-card>

    <!-- ç™½åå•è¡¨æ ¼ -->
    <el-card>
      <el-table :data="whitelistDomains" v-loading="loading">
        <el-table-column type="selection" width="55" />
        <el-table-column prop="domain" label="åŸŸå" min-width="200">
          <template #default="{ row }">
            <div class="domain-item">
              <el-icon v-if="row.is_wildcard" class="wildcard-icon"><Star /></el-icon>
              <span>{{ row.domain }}</span>
              <el-tag v-if="row.is_active" type="success" size="small">å·²å¯ç”¨</el-tag>
              <el-tag v-else type="info" size="small">å·²ç¦ç”¨</el-tag>
            </div>
          </template>
        </el-table-column>
        <el-table-column prop="match_count" label="åŒ¹é…æ¬¡æ•°" width="120" align="center" />
        <el-table-column prop="description" label="æè¿°" min-width="150" />
        <el-table-column prop="created_by" label="åˆ›å»ºäºº" width="120" />
        <el-table-column prop="created_at" label="åˆ›å»ºæ—¶é—´" width="180">
          <template #default="{ row }">
            {{ formatTime(row.created_at) }}
          </template>
        </el-table-column>
        <el-table-column label="æ“ä½œ" width="200" fixed="right">
          <template #default="{ row }">
            <el-button-group>
              <el-button type="text" size="small" @click="toggleDomain(row)">
                {{ row.is_active ? 'ç¦ç”¨' : 'å¯ç”¨' }}
              </el-button>
              <el-button type="text" size="small" @click="editDomain(row)">ç¼–è¾‘</el-button>
              <el-button type="text" size="small" @click="deleteDomain(row)" style="color: #f56c6c;">åˆ é™¤</el-button>
            </el-button-group>
          </template>
        </el-table-column>
      </el-table>
    </el-card>
  </div>
</template>

<script setup lang="ts">
import { ref, reactive, onMounted } from 'vue'
import { ElMessage, ElMessageBox } from 'element-plus'
import { whitelistApi } from '@/api/whitelist'

// å“åº”å¼æ•°æ®
const loading = ref(false)
const newDomain = ref('')
const whitelistDomains = ref([])

// æ·»åŠ åŸŸååˆ°ç™½åå•
const addDomain = async () => {
  if (!newDomain.value.trim()) {
    ElMessage.warning('è¯·è¾“å…¥åŸŸå')
    return
  }
  
  try {
    await whitelistApi.addDomain({
      domain: newDomain.value.trim(),
      description: 'æ‰‹åŠ¨æ·»åŠ ',
      is_active: true
    })
    
    ElMessage.success('åŸŸåå·²æ·»åŠ åˆ°ç™½åå•')
    newDomain.value = ''
    await loadWhitelist()
  } catch (error) {
    ElMessage.error('æ·»åŠ å¤±è´¥ï¼š' + error.message)
  }
}

// åŠ è½½ç™½åå•
const loadWhitelist = async () => {
  loading.value = true
  try {
    const response = await whitelistApi.getList()
    whitelistDomains.value = response.data
  } catch (error) {
    ElMessage.error('åŠ è½½ç™½åå•å¤±è´¥')
  } finally {
    loading.value = false
  }
}

// åˆ‡æ¢åŸŸåçŠ¶æ€
const toggleDomain = async (domain) => {
  try {
    await whitelistApi.updateDomain(domain.id, {
      is_active: !domain.is_active
    })
    
    domain.is_active = !domain.is_active
    ElMessage.success(`åŸŸåå·²${domain.is_active ? 'å¯ç”¨' : 'ç¦ç”¨'}`)
  } catch (error) {
    ElMessage.error('æ“ä½œå¤±è´¥')
  }
}

onMounted(() => {
  loadWhitelist()
})
</script>
```

**2. å®šæ—¶ä»»åŠ¡ç®¡ç†æ¨¡å—**
```vue
<!-- ScheduledTasks.vue -->
<template>
  <div class="scheduled-tasks">
    <div class="page-header">
      <h2>å®šæ—¶ä»»åŠ¡</h2>
      <p>ç®¡ç†è‡ªåŠ¨åŒ–æ‰«æä»»åŠ¡çš„è°ƒåº¦è®¡åˆ’</p>
    </div>

    <!-- åˆ›å»ºå®šæ—¶ä»»åŠ¡ -->
    <el-card class="create-task-card">
      <template #header>
        <span>åˆ›å»ºå®šæ—¶ä»»åŠ¡</span>
      </template>
      
      <el-form :model="taskForm" :rules="taskRules" ref="taskFormRef" label-width="120px">
        <el-row :gutter="16">
          <el-col :span="12">
            <el-form-item label="ä»»åŠ¡åç§°" prop="name">
              <el-input v-model="taskForm.name" placeholder="è¾“å…¥ä»»åŠ¡åç§°" />
            </el-form-item>
            <el-form-item label="ç›®æ ‡åŸŸå" prop="domain">
              <el-input v-model="taskForm.domain" placeholder="example.com" />
            </el-form-item>
            <el-form-item label="è°ƒåº¦è§„åˆ™" prop="cron_expression">
              <el-input v-model="taskForm.cron_expression" placeholder="0 0 2 * * ?">
                <template #append>
                  <el-button @click="showCronBuilder">å¯è§†åŒ–é…ç½®</el-button>
                </template>
              </el-input>
              <div class="cron-help">
                <small>Cronè¡¨è¾¾å¼: ç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨å¹´ï¼Œä¾‹å¦‚ï¼š0 0 2 * * ? è¡¨ç¤ºæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ</small>
              </div>
            </el-form-item>
          </el-col>
          <el-col :span="12">
            <el-form-item label="ä»»åŠ¡çŠ¶æ€">
              <el-switch v-model="taskForm.is_active" active-text="å¯ç”¨" inactive-text="ç¦ç”¨" />
            </el-form-item>
            <el-form-item label="å¤±è´¥é‡è¯•">
              <el-input-number v-model="taskForm.max_retries" :min="0" :max="5" />
            </el-form-item>
            <el-form-item label="è¶…æ—¶æ—¶é—´">
              <el-input-number v-model="taskForm.timeout_hours" :min="1" :max="24" />
              <span style="margin-left: 8px;">å°æ—¶</span>
            </el-form-item>
          </el-col>
        </el-row>
        
        <el-form-item>
          <el-button type="primary" @click="createTask">åˆ›å»ºä»»åŠ¡</el-button>
          <el-button @click="resetForm">é‡ç½®</el-button>
        </el-form-item>
      </el-form>
    </el-card>

    <!-- ä»»åŠ¡åˆ—è¡¨ -->
    <el-card>
      <template #header>
        <div class="card-header">
          <span>å®šæ—¶ä»»åŠ¡åˆ—è¡¨</span>
          <el-button-group>
            <el-button type="success" size="small" @click="startAllTasks">å¯åŠ¨æ‰€æœ‰</el-button>
            <el-button type="warning" size="small" @click="pauseAllTasks">æš‚åœæ‰€æœ‰</el-button>
          </el-button-group>
        </div>
      </template>
      
      <el-table :data="scheduledTasks" v-loading="loading">
        <el-table-column prop="name" label="ä»»åŠ¡åç§°" min-width="150" />
        <el-table-column prop="domain" label="ç›®æ ‡åŸŸå" min-width="150" />
        <el-table-column prop="cron_expression" label="Cronè¡¨è¾¾å¼" width="150" />
        <el-table-column prop="status" label="çŠ¶æ€" width="100">
          <template #default="{ row }">
            <el-tag :type="getStatusType(row.status)" size="small">
              {{ getStatusText(row.status) }}
            </el-tag>
          </template>
        </el-table-column>
        <el-table-column prop="next_run" label="ä¸‹æ¬¡æ‰§è¡Œ" width="180">
          <template #default="{ row }">
            {{ formatTime(row.next_run) }}
          </template>
        </el-table-column>
        <el-table-column prop="last_run" label="ä¸Šæ¬¡æ‰§è¡Œ" width="180">
          <template #default="{ row }">
            <span v-if="row.last_run">
              {{ formatTime(row.last_run) }}
            </span>
            <span v-else class="text-muted">ä»æœªæ‰§è¡Œ</span>
          </template>
        </el-table-column>
        <el-table-column label="æ“ä½œ" width="200" fixed="right">
          <template #default="{ row }">
            <el-button-group>
              <el-button type="text" size="small" @click="toggleTask(row)">
                {{ row.is_active ? 'æš‚åœ' : 'å¯åŠ¨' }}
              </el-button>
              <el-button type="text" size="small" @click="runNow(row)">ç«‹å³æ‰§è¡Œ</el-button>
              <el-button type="text" size="small" @click="editTask(row)">ç¼–è¾‘</el-button>
              <el-button type="text" size="small" @click="deleteTask(row)" style="color: #f56c6c;">åˆ é™¤</el-button>
            </el-button-group>
          </template>
        </el-table-column>
      </el-table>
    </el-card>
  </div>
</template>
```

**TODOåŠŸèƒ½å®ç°æ¸…å•**

**1. ç³»ç»Ÿé…ç½®ä¿å­˜åŠŸèƒ½**
```typescript
// ä¿®å¤SystemConfigPanel.vueä¸­çš„TODO
import { systemConfigApi } from '@/api/config'

// ä¿®å¤ä¿å­˜é…ç½®åŠŸèƒ½
const saveConfig = async () => {
  saving.value = true
  try {
    // å®é™…APIè°ƒç”¨æ›¿ä»£TODO
    await systemConfigApi.updateConfig(config)
    ElMessage.success('ç³»ç»Ÿé…ç½®ä¿å­˜æˆåŠŸ')
  } catch (error) {
    ElMessage.error('ä¿å­˜é…ç½®å¤±è´¥: ' + error.message)
  } finally {
    saving.value = false
  }
}

// ä¿®å¤ç³»ç»Ÿé‡å¯åŠŸèƒ½
const restartSystem = async () => {
  try {
    await ElMessageBox.confirm(
      'ç¡®å®šè¦é‡å¯ç³»ç»Ÿå—ï¼Ÿè¿™å°†ä¸­æ–­æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ã€‚',
      'ç¡®è®¤é‡å¯',
      {
        confirmButtonText: 'ç¡®å®š',
        cancelButtonText: 'å–æ¶ˆ',
        type: 'warning'
      }
    )

    restarting.value = true
    // å®é™…APIè°ƒç”¨æ›¿ä»£TODO
    await systemConfigApi.restartSystem()
    ElMessage.success('ç³»ç»Ÿé‡å¯æˆåŠŸ')
  } catch {
    // ç”¨æˆ·å–æ¶ˆæ“ä½œ
  } finally {
    restarting.value = false
  }
}
```

**2. é€šçŸ¥é…ç½®æµ‹è¯•åŠŸèƒ½**
```typescript
// ä¿®å¤NotificationConfigPanel.vueä¸­çš„TODO
import { notificationApi } from '@/api/config'

// å‘é€æµ‹è¯•é€šçŸ¥
const testNotification = async () => {
  if (!config.email_enabled) {
    ElMessage.warning('è¯·å…ˆå¯ç”¨é‚®ä»¶é€šçŸ¥')
    return
  }
  
  if (config.recipient_emails.length === 0) {
    ElMessage.warning('è¯·è‡³å°‘æ·»åŠ ä¸€ä¸ªæ¥æ”¶äººé‚®ç®±')
    return
  }

  testing.value = true
  try {
    // å®é™…APIè°ƒç”¨æ›¿ä»£TODO
    const response = await notificationApi.testConfig('email')
    if (response.data.success) {
      ElMessage.success('æµ‹è¯•é€šçŸ¥å‘é€æˆåŠŸï¼Œè¯·æ£€æŸ¥é‚®ç®±')
    } else {
      ElMessage.error('æµ‹è¯•å¤±è´¥ï¼š' + response.data.message)
    }
  } catch (error) {
    ElMessage.error('å‘é€æµ‹è¯•é€šçŸ¥å¤±è´¥')
  } finally {
    testing.value = false
  }
}
```

**3. ç”¨æˆ·æ³¨å†ŒAPIå®ç°**
```typescript
// ä¿®å¤Register.vueä¸­çš„TODO  
import { authApi } from '@/api/auth'

const handleRegister = async () => {
  if (!registerForm.agreeToTerms) {
    ElMessage.warning('è¯·é˜…è¯»å¹¶åŒæ„ç”¨æˆ·åè®®å’Œéšç§æ”¿ç­–')
    return
  }

  try {
    await registerFormRef.value.validate()
    
    loading.value = true
    
    // å®é™…APIè°ƒç”¨æ›¿ä»£TODO
    await authApi.register({
      username: registerForm.username,
      email: registerForm.email,
      password: registerForm.password,
      full_name: registerForm.realName,
      organization: registerForm.organization
    })
    
    ElMessage.success('æ³¨å†ŒæˆåŠŸï¼è¯·ç™»å½•æ‚¨çš„è´¦æˆ·')
    
    // è·³è½¬åˆ°ç™»å½•é¡µé¢
    router.push('/login')
  } catch (error: any) {
    if (error.response?.data?.detail) {
      ElMessage.error(error.response.data.detail)
    } else {
      ElMessage.error('æ³¨å†Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•')
    }
  } finally {
    loading.value = false
  }
}
```

**è·¯ç”±é…ç½®æ›´æ–°**
```typescript
// æ›´æ–°router/index.tsï¼Œæ·»åŠ æ–°æ¨¡å—è·¯ç”±
const DomainWhitelist = () => import('@/views/admin/DomainWhitelist.vue')
const IPBlacklist = () => import('@/views/admin/IPBlacklist.vue')
const ScheduledTasks = () => import('@/views/admin/ScheduledTasks.vue')
const AuditLogs = () => import('@/views/admin/AuditLogs.vue')

// åœ¨routesä¸­æ·»åŠ ç®¡ç†å‘˜è·¯ç”±
{
  path: 'admin',
  name: 'Admin',
  meta: {
    title: 'ç®¡ç†ä¸­å¿ƒ',
    icon: 'Setting',
    roles: ['admin']
  },
  children: [
    {
      path: 'domain-whitelist',
      name: 'DomainWhitelist',
      component: DomainWhitelist,
      meta: {
        title: 'åŸŸåç™½åå•',
        icon: 'Shield'
      }
    },
    {
      path: 'ip-blacklist',
      name: 'IPBlacklist',
      component: IPBlacklist,
      meta: {
        title: 'IPé»‘åå•',
        icon: 'Warning'
      }
    },
    {
      path: 'scheduled-tasks',
      name: 'ScheduledTasks',
      component: ScheduledTasks,
      meta: {
        title: 'å®šæ—¶ä»»åŠ¡',
        icon: 'Timer'
      }
    },
    {
      path: 'audit-logs',
      name: 'AuditLogs',
      component: AuditLogs,
      meta: {
        title: 'å®¡è®¡æ—¥å¿—',
        icon: 'Document'
      }
    }
  ]
}
```
```

## 4. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 4.1 æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

#### ç´¢å¼•ä¼˜åŒ–ç­–ç•¥
```sql
-- ç°æœ‰ç´¢å¼•åˆ†æ
CREATE INDEX idx_scan_tasks_user_status ON scan_tasks(user_id, status);
CREATE INDEX idx_scan_tasks_created_at ON scan_tasks(created_at DESC);
CREATE INDEX idx_violation_records_task_risk ON violation_records(task_id, risk_level);

-- å»ºè®®æ–°å¢ç´¢å¼•
CREATE INDEX idx_subdomain_records_task_accessible ON subdomain_records(task_id, is_accessible);
CREATE INDEX idx_third_party_domains_risk_type ON third_party_domains(risk_level, domain_type);
CREATE INDEX idx_task_logs_task_level_created ON task_logs(task_id, level, created_at DESC);
```

#### æŸ¥è¯¢ä¼˜åŒ–
- **åˆ†é¡µä¼˜åŒ–**: ä½¿ç”¨cursor-based paginationæ›¿ä»£offset
- **å…³è”æŸ¥è¯¢**: ä¼˜åŒ–N+1æŸ¥è¯¢é—®é¢˜
- **æ•°æ®åˆ†åŒº**: å¤§è¡¨æŒ‰æ—¶é—´åˆ†åŒºå­˜å‚¨
- **è¯»å†™åˆ†ç¦»**: ä¸»ä»æ•°æ®åº“æ¶æ„

### 4.2 ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

#### Redisç¼“å­˜å±‚è®¾è®¡
```mermaid
graph LR
    A[Application Layer] --> B[L1: Memory Cache]
    B --> C[L2: Redis Cache]
    C --> D[L3: Database]
    
    E[Cache Strategy] --> F[Task Status: TTL 1h]
    E --> G[User Sessions: TTL 8h]
    E --> H[AI Results: TTL 24h]
    E --> I[Domain Info: TTL 7d]
```

#### ç¼“å­˜ç­–ç•¥
- **ä»»åŠ¡çŠ¶æ€ç¼“å­˜**: å®æ—¶ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
- **ç»“æœç¼“å­˜**: AIåˆ†æç»“æœç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
- **é…ç½®ç¼“å­˜**: ç”¨æˆ·é…ç½®ä¿¡æ¯ç¼“å­˜
- **ç»Ÿè®¡æ•°æ®ç¼“å­˜**: Dashboardç»Ÿè®¡æ•°æ®ç¼“å­˜

### 4.3 å¹¶å‘æ€§èƒ½ä¼˜åŒ–

#### å¼‚æ­¥å¤„ç†ä¼˜åŒ–
```python
# ç°æœ‰ä»»åŠ¡æ‰§è¡Œæ¨¡å¼
async def execute_scan_sequential():
    subdomains = await discover_subdomains()
    links = await crawl_links()
    content = await capture_content()
    analysis = await ai_analysis()

# ä¼˜åŒ–åå¹¶å‘æ‰§è¡Œæ¨¡å¼  
async def execute_scan_concurrent():
    # å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡
    tasks = [
        discover_subdomains(),
        crawl_initial_links(), 
        identify_third_parties()
    ]
    results = await asyncio.gather(*tasks)
    
    # Pipelineå¼å¤„ç†
    async for page_batch in crawl_pages_stream():
        await process_batch_concurrent(page_batch)
```

#### èµ„æºæ± ä¼˜åŒ–
- **æ•°æ®åº“è¿æ¥æ± **: åŠ¨æ€è°ƒæ•´è¿æ¥æ± å¤§å°
- **æµè§ˆå™¨å®ä¾‹æ± **: å¤ç”¨Playwrightæµè§ˆå™¨å®ä¾‹
- **HTTPå®¢æˆ·ç«¯æ± **: å¤ç”¨aiohttpä¼šè¯
- **AI APIé™æµ**: æ™ºèƒ½è¯·æ±‚é¢‘ç‡æ§åˆ¶

## 5. ç³»ç»Ÿä¼˜åŒ–é‡æ„

### 5.1 æ¶æ„å±‚é¢ä¼˜åŒ–

#### 5.1.1 å¾®æœåŠ¡åŒ–æ”¹é€ 
```mermaid
graph TB
    subgraph "API Gateway"
        A[Nginx/Kong]
    end
    
    subgraph "Core Services"
        B[Auth Service]
        C[Task Service] 
        D[Scan Service]
        E[Analysis Service]
        F[Report Service]
    end
    
    subgraph "Storage Layer"
        G[PostgreSQL Cluster]
        H[Redis Cluster]
        I[MinIO/S3]
    end
    
    A --> B
    A --> C
    A --> D
    A --> E  
    A --> F
    
    B --> G
    C --> G
    D --> H
    E --> I
```

#### 5.1.2 é…ç½®ç®¡ç†ä¼˜åŒ–
```yaml
# config/environments/production.yaml
app:
  name: "AI Content Security"
  version: "2.0.0"
  debug: false

database:
  primary:
    url: "${DATABASE_PRIMARY_URL}"
    pool_size: 20
    max_overflow: 30
  replica:
    url: "${DATABASE_REPLICA_URL}" 
    pool_size: 10

cache:
  redis:
    cluster_urls: ["${REDIS_NODE_1}", "${REDIS_NODE_2}", "${REDIS_NODE_3}"]
    password: "${REDIS_PASSWORD}"
    
ai_models:
  openai:
    api_key: "${OPENAI_API_KEY}"
    rate_limit: 100
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    rate_limit: 50
```

### 5.2 ä»£ç è´¨é‡æå‡

#### 5.2.1 ä¾èµ–æ³¨å…¥é‡æ„
```python
# ä¼˜åŒ–å‰ï¼šç¡¬ç¼–ç ä¾èµ–
class ScanTaskExecutor:
    def __init__(self, task_id: str, user_id: str):
        self.subdomain_engine = SubdomainDiscoveryEngine(task_id, user_id)
        self.crawler_engine = LinkCrawlerEngine(task_id, user_id)
        # ...

# ä¼˜åŒ–åï¼šä¾èµ–æ³¨å…¥
@dataclass
class ScanEngines:
    subdomain_engine: SubdomainDiscoveryEngine
    crawler_engine: LinkCrawlerEngine
    identifier_engine: ThirdPartyIdentifierEngine
    capture_engine: ContentCaptureEngine
    ai_engine: AIAnalysisEngine

class ScanTaskExecutor:
    def __init__(self, task_id: str, user_id: str, engines: ScanEngines):
        self.task_id = task_id
        self.user_id = user_id
        self.engines = engines
```

#### 5.2.2 é”™è¯¯å¤„ç†æ ‡å‡†åŒ–
```python
# ç»Ÿä¸€å¼‚å¸¸å¤„ç†ç³»ç»Ÿ
class DomainScanException(Exception):
    def __init__(self, message: str, error_code: str, context: dict = None):
        self.message = message
        self.error_code = error_code  
        self.context = context or {}
        super().__init__(message)

class SubdomainDiscoveryError(DomainScanException):
    pass

class AIAnalysisError(DomainScanException):  
    pass

# å…¨å±€å¼‚å¸¸å¤„ç†å™¨
@app.exception_handler(DomainScanException)
async def domain_scan_exception_handler(request: Request, exc: DomainScanException):
    return JSONResponse(
        status_code=400,
        content={
            "error_code": exc.error_code,
            "message": exc.message,
            "context": exc.context,
            "request_id": request.state.request_id
        }
    )
```

### 5.3 å‰ç«¯ä¼˜åŒ–é‡æ„

#### 5.3.1 ç»„ä»¶åŒ–æ¶æ„ä¼˜åŒ–
```typescript
// ä¼˜åŒ–å‰ï¼šå•ä¸€å¤§ç»„ä»¶
// TaskList.vue - 394è¡Œä»£ç 

// ä¼˜åŒ–åï¼šç»„ä»¶æ‹†åˆ†
// TaskList.vue -> TaskListContainer.vue
//              -> TaskListHeader.vue  
//              -> TaskListFilters.vue
//              -> TaskListTable.vue
//              -> TaskListPagination.vue

// å¯å¤ç”¨ç»„ä»¶è®¾è®¡
interface BaseTableProps<T> {
  data: T[]
  loading: boolean
  columns: TableColumn<T>[]
  pagination?: PaginationConfig
}

const BaseTable = defineComponent<BaseTableProps>({
  // é€šç”¨è¡¨æ ¼ç»„ä»¶å®ç°
})
```

#### 5.3.2 çŠ¶æ€ç®¡ç†ä¼˜åŒ–
```typescript
// ä¼˜åŒ– Pinia Store ç»“æ„
export const useTaskStore = defineStore('tasks', () => {
  // State
  const tasks = ref<Task[]>([])
  const currentTask = ref<Task | null>(null)
  const filters = ref<TaskFilters>({})
  const pagination = ref<PaginationState>({
    page: 1,
    pageSize: 20, 
    total: 0
  })
  
  // Actions  
  const fetchTasks = async (params?: TaskQueryParams) => {
    // å®ç°æ•°æ®è·å–é€»è¾‘
  }
  
  const createTask = async (taskData: CreateTaskRequest) => {
    // å®ç°ä»»åŠ¡åˆ›å»ºé€»è¾‘
  }
  
  // Getters
  const runningTasks = computed(() => 
    tasks.value.filter(task => task.status === 'running')
  )
  
  return {
    // State
    tasks: readonly(tasks),
    currentTask: readonly(currentTask),
    filters,
    pagination,
    
    // Actions
    fetchTasks,
    createTask,
    
    // Getters  
    runningTasks
  }
})
```

## 6. éƒ¨ç½²è¿ç»´ä¼˜åŒ–

### 6.1 å®¹å™¨åŒ–éƒ¨ç½²ä¼˜åŒ–

#### Dockerä¼˜åŒ–é…ç½®
```dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
FROM node:18-alpine AS frontend-builder
WORKDIR /app/frontend
COPY frontend/package*.json ./
RUN npm ci --only=production && npm cache clean --force
COPY frontend/ ./
RUN npm run build

FROM python:3.11-slim AS backend-builder  
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

FROM python:3.11-slim AS runtime
RUN apt-get update && apt-get install -y \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*
    
WORKDIR /app
COPY --from=backend-builder /root/.local /root/.local
COPY --from=frontend-builder /app/frontend/dist ./frontend/dist
COPY . .

ENV PATH=/root/.local/bin:$PATH
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Kuberneteséƒ¨ç½²æ¸…å•
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-content-security
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-content-security
  template:
    metadata:
      labels:
        app: ai-content-security
    spec:
      containers:
      - name: app
        image: ai-content-security:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"  
            cpu: "500m"
```

### 6.2 ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

#### ç›‘æ§æŒ‡æ ‡é…ç½®
```python
# Prometheusç›‘æ§æŒ‡æ ‡æ‰©å±•
from prometheus_client import Counter, Histogram, Gauge

# ä¸šåŠ¡æŒ‡æ ‡
SCAN_TASKS_CREATED = Counter('scan_tasks_created_total', 'Total scan tasks created', ['user_id'])
SCAN_DURATION = Histogram('scan_duration_seconds', 'Scan execution duration', ['domain'])
AI_API_CALLS = Counter('ai_api_calls_total', 'AI API calls', ['model', 'status'])
VIOLATION_DETECTED = Counter('violations_detected_total', 'Violations detected', ['type', 'severity'])

# ç³»ç»ŸæŒ‡æ ‡  
ACTIVE_CONNECTIONS = Gauge('websocket_connections_active', 'Active WebSocket connections')
QUEUE_SIZE = Gauge('celery_queue_size', 'Celery queue size', ['queue'])
```

#### å‘Šè­¦è§„åˆ™é…ç½®
```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
- name: ai-content-security
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate detected"
      
  - alert: TaskQueueBacklog  
    expr: celery_queue_size > 100
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Task queue backlog is growing"
      
  - alert: AIAPIFailure
    expr: rate(ai_api_calls_total{status="error"}[10m]) > 0.2  
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "AI API failure rate is high"
```

## 7. å®‰å…¨æ€§å¼ºåŒ–

### 7.1 APIå®‰å…¨ä¼˜åŒ–

#### è®¤è¯æˆæƒå¢å¼º
```python
# JWT Tokenä¼˜åŒ–
class TokenManager:
    def __init__(self):
        self.refresh_tokens = {}  # å­˜å‚¨åœ¨Redisä¸­
        
    async def create_token_pair(self, user: User) -> TokenPair:
        access_token = create_access_token(
            data={"sub": user.id, "role": user.role},
            expires_delta=timedelta(minutes=15)  # çŸ­æœŸè®¿é—®ä»¤ç‰Œ
        )
        refresh_token = create_refresh_token(
            data={"sub": user.id},
            expires_delta=timedelta(days=7)
        )
        await self.store_refresh_token(user.id, refresh_token)
        return TokenPair(access_token, refresh_token)
        
# APIé™æµå¢å¼º
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.route("/api/v1/tasks")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿ10æ¬¡è¯·æ±‚
async def create_task(request: Request, task_data: CreateTaskRequest):
    pass
```

#### æ•°æ®åŠ å¯†ä¼˜åŒ–
```python
# æ•æ„Ÿæ•°æ®åŠ å¯†å­˜å‚¨
class SecureDataManager:
    def __init__(self, encryption_key: bytes):
        self.fernet = Fernet(encryption_key)
        
    def encrypt_field(self, data: str) -> str:
        """åŠ å¯†æ•æ„Ÿå­—æ®µ"""
        return self.fernet.encrypt(data.encode()).decode()
        
    def decrypt_field(self, encrypted_data: str) -> str:
        """è§£å¯†æ•æ„Ÿå­—æ®µ"""
        return self.fernet.decrypt(encrypted_data.encode()).decode()
        
# æ•°æ®åº“å­—æ®µè‡ªåŠ¨åŠ å¯†
class EncryptedColumn(TypeDecorator):
    impl = Text
    
    def process_bind_param(self, value, dialect):
        if value is not None:
            return secure_data_manager.encrypt_field(value)
        return value
        
    def process_result_value(self, value, dialect):
        if value is not None:
            return secure_data_manager.decrypt_field(value)
        return value
```

### 7.2 è¾“å…¥éªŒè¯ä¸é˜²æŠ¤

#### SQLæ³¨å…¥é˜²æŠ¤
```python
# å‚æ•°åŒ–æŸ¥è¯¢å¼ºåˆ¶ä½¿ç”¨
class SafeQueryBuilder:
    @staticmethod
    def build_filter_query(filters: dict) -> tuple[str, list]:
        conditions = []
        params = []
        
        for key, value in filters.items():
            if key in ALLOWED_FILTER_FIELDS:
                conditions.append(f"{key} = ?")
                params.append(value)
                
        return " AND ".join(conditions), params
```

#### XSSé˜²æŠ¤
```python
# è¾“å‡ºå†…å®¹è¿‡æ»¤
from bleach import clean

def sanitize_html_content(content: str) -> str:
    """æ¸…ç†HTMLå†…å®¹é˜²æ­¢XSS"""
    allowed_tags = ['p', 'br', 'strong', 'em']
    return clean(content, tags=allowed_tags, strip=True)
```

## 8. æµ‹è¯•ç­–ç•¥å®Œå–„

### 8.1 æµ‹è¯•é‡‘å­—å¡”

```mermaid
pyramid
    title Testing Strategy
    
    "E2E Tests (5%)" : 10 : "Complete user workflows"
    "Integration Tests (20%)" : 30 : "API & Database integration"
    "Unit Tests (75%)" : 60 : "Individual components"
```

#### å•å…ƒæµ‹è¯•å¢å¼º
```python
# å¼•æ“æ¨¡å—æµ‹è¯•
@pytest.mark.asyncio
class TestSubdomainDiscoveryEngine:
    @pytest.fixture
    def engine(self):
        return SubdomainDiscoveryEngine("test-task", "test-user")
        
    async def test_discover_subdomains_dns(self, engine):
        # Mock DNS æŸ¥è¯¢
        with patch('dns.resolver.resolve') as mock_resolve:
            mock_resolve.return_value = [MockDNSRecord("sub.example.com")]
            
            results = await engine.discover_dns_subdomains("example.com")
            
            assert len(results) == 1
            assert results[0].subdomain == "sub.example.com"
            
    async def test_discover_subdomains_certificate(self, engine):
        # Mock Certificate Transparency API
        with patch('aiohttp.ClientSession.get') as mock_get:
            mock_response = AsyncMock()
            mock_response.json.return_value = {
                "entries": [{"name_value": "api.example.com\nwww.example.com"}]
            }
            mock_get.return_value.__aenter__.return_value = mock_response
            
            results = await engine.discover_certificate_subdomains("example.com")
            
            assert "api.example.com" in [r.subdomain for r in results]
```

#### é›†æˆæµ‹è¯•æ‰©å±•
```python
# APIé›†æˆæµ‹è¯•
@pytest.mark.asyncio
class TestTaskAPI:
    async def test_create_scan_task_flow(self, client, auth_headers, db_session):
        # åˆ›å»ºä»»åŠ¡
        task_data = {
            "target_domain": "example.com",
            "task_name": "Test Scan",
            "config": {"subdomain_discovery_enabled": True}
        }
        
        response = await client.post(
            "/api/v1/tasks",
            json=task_data,
            headers=auth_headers
        )
        
        assert response.status_code == 201
        task = response.json()
        assert task["target_domain"] == "example.com"
        
        # éªŒè¯æ•°æ®åº“è®°å½•
        db_task = await db_session.get(ScanTask, task["id"])
        assert db_task is not None
        assert db_task.status == TaskStatus.PENDING
```

### 8.2 æ€§èƒ½æµ‹è¯•

```python
# è´Ÿè½½æµ‹è¯•
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor

class LoadTestRunner:
    def __init__(self, base_url: str, concurrent_users: int = 50):
        self.base_url = base_url
        self.concurrent_users = concurrent_users
        
    async def simulate_user_session(self, user_id: int):
        """æ¨¡æ‹Ÿç”¨æˆ·ä¼šè¯"""
        async with aiohttp.ClientSession() as session:
            # ç™»å½•
            login_response = await session.post(
                f"{self.base_url}/api/v1/auth/login",
                json={"username": f"user{user_id}", "password": "testpass"}
            )
            
            if login_response.status == 200:
                token = (await login_response.json())["access_token"]
                headers = {"Authorization": f"Bearer {token}"}
                
                # åˆ›å»ºä»»åŠ¡
                await session.post(
                    f"{self.base_url}/api/v1/tasks",
                    json={
                        "target_domain": f"test{user_id}.example.com",
                        "config": {"subdomain_discovery_enabled": True}
                    },
                    headers=headers
                )
                
    async def run_load_test(self, duration_minutes: int = 5):
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        tasks = []
        
        for user_id in range(self.concurrent_users):
            task = asyncio.create_task(self.simulate_user_session(user_id))
            tasks.append(task)
            
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        await asyncio.wait_for(
            asyncio.gather(*tasks, return_exceptions=True),
            timeout=duration_minutes * 60
        )
```

## 9. è¯¦ç»†å®æ–½ä¼˜åŒ–è®¡åˆ’

### 9.1 å·¥ä½œåˆ†è§£ç»“æ„ (WBS)

```mermaid
mindmap
  root((ä¼˜åŒ–é¡¹ç›®))
    Phase1[åŸºç¡€ä¼˜åŒ–]
      æ€§èƒ½ä¼˜åŒ–
        æ•°æ®åº“ç´¢å¼•
        æŸ¥è¯¢ä¼˜åŒ–
        ç¼“å­˜å®ç°
      ä»£ç é‡æ„
        ä¾èµ–æ³¨å…¥
        é”™è¯¯å¤„ç†
        å¹¶å‘å®‰å…¨
      æµ‹è¯•å®Œå–„
        å•å…ƒæµ‹è¯•
        é›†æˆæµ‹è¯•
    Phase2[åŠŸèƒ½æ‹“å±•] 
      é«˜çº§æ‰«æ
        å®šæ—¶ç›‘æ§
        å¤šåª’ä½“åˆ†æ
        è‡ªå®šä¹‰è§„åˆ™
      AIå¢å¼º
        å¤šæ¨¡å‹æ”¯æŒ
        æœ¬åœ°éƒ¨ç½²
        æ™ºèƒ½è·¯ç”±
      ä¼ä¸šåŠŸèƒ½
        å¤šç§Ÿæˆ·
        APIå¼€æ”¾
        æƒé™ç®¡ç†
    Phase3[æ¶æ„å‡çº§]
      å¾®æœåŠ¡åŒ–
        æœåŠ¡æ‹†åˆ†
        APIç½‘å…³
        é…ç½®ä¸­å¿ƒ
      è¿ç»´èƒ½åŠ›
        å®¹å™¨åŒ–
        ç›‘æ§å‘Šè­¦
        CI/CD
```

### 9.2 è¯¦ç»†æ—¶é—´çº¿ä¸é‡Œç¨‹ç¢‘

**Phase 1: åŸºç¡€ä¼˜åŒ– (4-6å‘¨)**

| é‡Œç¨‹ç¢‘ | å·¥ä½œå†…å®¹ | è´Ÿè´£äºº | å®Œæˆæ—¶é—´ | å…³é”®æŒ‡æ ‡ |
|--------|----------|--------|----------|----------|
| M1.1 | æ•°æ®åº“æ€§èƒ½ä¼˜åŒ– | åç«¯å¼€å‘ | ç¬¬2å‘¨ | æŸ¥è¯¢å“åº”æ—¶é—´<100ms |
| M1.2 | ç¼“å­˜å±‚å®ç° | åç«¯å¼€å‘ | ç¬¬3å‘¨ | ç¼“å­˜å‘½ä¸­ç‡>80% |
| M1.3 | å‰ç«¯ç»„ä»¶é‡æ„ | å‰ç«¯å¼€å‘ | ç¬¬4å‘¨ | é¡µé¢åŠ è½½æ—¶é—´<3s |
| M1.4 | é”™è¯¯å¤„ç†ç»Ÿä¸€ | å…¨æ ˆå¼€å‘ | ç¬¬5å‘¨ | å¼‚å¸¸è¦†ç›–ç‡>95% |
| M1.5 | æµ‹è¯•è¦†ç›–å®Œå–„ | QAå›¢é˜Ÿ | ç¬¬6å‘¨ | ä»£ç è¦†ç›–ç‡>80% |

**Phase 2: åŠŸèƒ½æ‹“å±• (6-8å‘¨)**

| é‡Œç¨‹ç¢‘ | å·¥ä½œå†…å®¹ | è´Ÿè´£äºº | å®Œæˆæ—¶é—´ | å…³é”®æŒ‡æ ‡ |
|--------|----------|--------|----------|----------|
| M2.1 | å®šæ—¶æ‰«æç³»ç»Ÿ | åç«¯å¼€å‘ | ç¬¬2å‘¨ | æ”¯æŒCronè¡¨è¾¾å¼è°ƒåº¦ |
| M2.2 | å¤šAIæ¨¡å‹é›†æˆ | AIå¼€å‘ | ç¬¬4å‘¨ | æ”¯æŒ3ç§AIæœåŠ¡ |
| M2.3 | å¤šç§Ÿæˆ·æ¶æ„ | æ¶æ„å¸ˆ | ç¬¬6å‘¨ | æ”¯æŒç»„ç»‡éš”ç¦» |
| M2.4 | APIå¼€æ”¾å¹³å° | APIå¼€å‘ | ç¬¬7å‘¨ | æä¾›å®Œæ•´REST API |
| M2.5 | ä¼ä¸šçº§æƒé™ | å®‰å…¨å¼€å‘ | ç¬¬8å‘¨ | RBACæƒé™ä½“ç³» |

**Phase 3: æ¶æ„å‡çº§ (8-12å‘¨)**

| é‡Œç¨‹ç¢‘ | å·¥ä½œå†…å®¹ | è´Ÿè´£äºº | å®Œæˆæ—¶é—´ | å…³é”®æŒ‡æ ‡ |
|--------|----------|--------|----------|----------|
| M3.1 | å¾®æœåŠ¡æ‹†åˆ† | æ¶æ„å¸ˆ | ç¬¬4å‘¨ | 5ä¸ªç‹¬ç«‹æœåŠ¡ |
| M3.2 | æœåŠ¡ç½‘å…³éƒ¨ç½² | DevOps | ç¬¬6å‘¨ | ç»Ÿä¸€APIå…¥å£ |
| M3.3 | ç›‘æ§å‘Šè­¦ç³»ç»Ÿ | è¿ç»´å·¥ç¨‹å¸ˆ | ç¬¬8å‘¨ | 99%å¯ç”¨æ€§ç›‘æ§ |
| M3.4 | è‡ªåŠ¨åŒ–éƒ¨ç½² | DevOps | ç¬¬10å‘¨ | CI/CD Pipeline |
| M3.5 | ç”Ÿäº§ç¯å¢ƒä¸Šçº¿ | å…¨å›¢é˜Ÿ | ç¬¬12å‘¨ | SLA 99.9% |

### 9.3 å…³é”®æŠ€æœ¯å†³ç­–

#### æŠ€æœ¯é€‰å‹å†³ç­–çŸ©é˜µ

| æŠ€æœ¯é¢†åŸŸ | å€™é€‰æ–¹æ¡ˆ | é€‰æ‹©ç»“æœ | å†³ç­–å› ç´  | é£é™©è¯„ä¼° |
|---------|----------|----------|----------|----------|
| å¾®æœåŠ¡ç½‘å…³ | Kong vs Nginx vs Istio | **Kong** | æ˜“ç”¨æ€§ã€æ’ä»¶ç”Ÿæ€ | ä½é£é™© |
| æ¶ˆæ¯é˜Ÿåˆ— | RabbitMQ vs Kafka vs Redis | **Redis Stream** | å­¦ä¹ æˆæœ¬ã€è¿ç»´å¤æ‚åº¦ | ä¸­é£é™© |
| ç›‘æ§ç³»ç»Ÿ | Prometheus vs DataDog | **Prometheus** | å¼€æºã€æˆæœ¬æ§åˆ¶ | ä½é£é™© |
| AIæ¨¡å‹ç®¡ç† | MLflow vs Kubeflow | **MLflow** | è½»é‡çº§ã€å¿«é€Ÿä¸Šæ‰‹ | ä¸­é£é™© |
| å®¹å™¨ç¼–æ’ | Docker Swarm vs K8s | **Kubernetes** | ç”Ÿæ€æˆç†Ÿåº¦ | é«˜é£é™© |

#### æ•°æ®è¿ç§»ç­–ç•¥

```python
# æ¸è¿›å¼æ•°æ®è¿ç§»æ–¹æ¡ˆ
class DataMigrationManager:
    async def execute_phased_migration(self):
        """åˆ†é˜¶æ®µæ•°æ®è¿ç§»"""
        phases = [
            self.migrate_user_data,      # Phase 1: ç”¨æˆ·æ•°æ®
            self.migrate_task_data,      # Phase 2: ä»»åŠ¡æ•°æ®  
            self.migrate_result_data,    # Phase 3: ç»“æœæ•°æ®
            self.migrate_config_data,    # Phase 4: é…ç½®æ•°æ®
        ]
        
        for phase_func in phases:
            try:
                await self.create_backup_point()
                await phase_func()
                await self.verify_migration()
                logger.info(f"Migration phase {phase_func.__name__} completed")
            except Exception as e:
                await self.rollback_to_backup()
                raise MigrationError(f"Failed at {phase_func.__name__}: {e}")
```

### 9.4 é£é™©æ§åˆ¶ä¸åº”æ€¥é¢„æ¡ˆ

#### é£é™©è¯†åˆ«çŸ©é˜µ

| é£é™©ç±»å‹ | é£é™©æè¿° | æ¦‚ç‡ | å½±å“ | é£é™©ç­‰çº§ | åº”å¯¹ç­–ç•¥ |
|---------|----------|------|------|----------|----------|
| æŠ€æœ¯é£é™© | å¾®æœåŠ¡æ‹†åˆ†å¤æ‚åº¦è¶…é¢„æœŸ | ä¸­ | é«˜ | **é«˜** | æ¸è¿›å¼æ‹†åˆ†ã€ä¿ç•™å›æ»šæ–¹æ¡ˆ |
| æ€§èƒ½é£é™© | æ•°æ®åº“è¿ç§»å½±å“æœåŠ¡ | ä½ | é«˜ | **ä¸­** | ç¦»çº¿è¿ç§»ã€ä¸»ä»åˆ‡æ¢ |
| äººå‘˜é£é™© | æ ¸å¿ƒå¼€å‘äººå‘˜ç¦»èŒ | ä½ | é«˜ | **ä¸­** | çŸ¥è¯†æ–‡æ¡£åŒ–ã€äº¤å‰åŸ¹è®­ |
| æ—¶é—´é£é™© | åŠŸèƒ½å¼€å‘è¿›åº¦å»¶æœŸ | ä¸­ | ä¸­ | **ä¸­** | æ•æ·è¿­ä»£ã€MVPä¼˜å…ˆ |
| é›†æˆé£é™© | ç¬¬ä¸‰æ–¹AIæœåŠ¡ä¸ç¨³å®š | ä¸­ | ä¸­ | **ä¸­** | å¤šä¾›åº”å•†å¤‡é€‰ã€é™çº§æ–¹æ¡ˆ |

#### åº”æ€¥é¢„æ¡ˆ

**æ•°æ®åº“æ€§èƒ½é—®é¢˜åº”æ€¥é¢„æ¡ˆ**
```bash
#!/bin/bash
# æ•°æ®åº“åº”æ€¥å¤„ç†è„šæœ¬

# 1. ç«‹å³æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
psql -h $DB_HOST -c "SELECT * FROM pg_stat_activity WHERE state = 'active';"

# 2. ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
psql -h $DB_HOST -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND query_start < NOW() - INTERVAL '5 minutes';"

# 3. å¯ç”¨åªè¯»æ¨¡å¼ï¼ˆç´§æ€¥æƒ…å†µï¼‰
echo "READ_ONLY_MODE=true" >> /app/.env
sudo systemctl reload ai-content-security

# 4. é€šçŸ¥ç›¸å…³äººå‘˜
curl -X POST $SLACK_WEBHOOK -d '{"text":"æ•°æ®åº“æ€§èƒ½å‘Šè­¦å·²è§¦å‘åº”æ€¥é¢„æ¡ˆ"}'
```

### 9.5 è´¨é‡ä¿è¯ä½“ç³»

#### ä»£ç è´¨é‡é—¨ç¦

```yaml
# .gitlab-ci.yml è´¨é‡é—¨ç¦é…ç½®
quality_gate:
  stage: test
  script:
    # 1. ä»£ç è¦†ç›–ç‡æ£€æŸ¥
    - pytest --cov=app --cov-report=xml --cov-fail-under=80
    
    # 2. ä»£ç é£æ ¼æ£€æŸ¥
    - black --check app/
    - isort --check-only app/
    - flake8 app/
    
    # 3. ç±»å‹æ£€æŸ¥
    - mypy app/
    
    # 4. å®‰å…¨æ¼æ´æ‰«æ
    - bandit -r app/
    
    # 5. ä¾èµ–æ¼æ´æ£€æŸ¥
    - safety check
    
  only:
    - merge_requests
  allow_failure: false
```

#### æ€§èƒ½å›å½’æµ‹è¯•

```python
# æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶
class PerformanceBenchmark:
    async def test_api_response_time(self):
        """APIå“åº”æ—¶é—´åŸºå‡†æµ‹è¯•"""
        endpoints = [
            "/api/v1/tasks",
            "/api/v1/domains", 
            "/api/v1/reports"
        ]
        
        for endpoint in endpoints:
            response_times = []
            for _ in range(100):  # 100æ¬¡è¯·æ±‚æµ‹è¯•
                start_time = time.time()
                response = await self.client.get(endpoint)
                response_time = time.time() - start_time
                response_times.append(response_time)
            
            p95_time = np.percentile(response_times, 95)
            assert p95_time < 0.2, f"{endpoint} P95å“åº”æ—¶é—´è¶…æ ‡: {p95_time}s"
    
    async def test_concurrent_scan_performance(self):
        """å¹¶å‘æ‰«ææ€§èƒ½æµ‹è¯•"""
        # æ¨¡æ‹Ÿ100ä¸ªå¹¶å‘æ‰«æä»»åŠ¡
        tasks = []
        for i in range(100):
            task = asyncio.create_task(
                self.create_and_monitor_scan_task(f"test{i}.example.com")
            )
            tasks.append(task)
        
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        success_count = sum(1 for r in results if not isinstance(r, Exception))
        success_rate = success_count / len(tasks)
        
        assert success_rate > 0.95, f"å¹¶å‘æˆåŠŸç‡è¿‡ä½: {success_rate}"
        assert total_time < 300, f"å¹¶å‘å¤„ç†æ—¶é—´è¿‡é•¿: {total_time}s"
```

---

## 10. é¡¹ç›®æˆåŠŸéªŒæ”¶æ ‡å‡†

### 10.1 æŠ€æœ¯æŒ‡æ ‡éªŒæ”¶

#### æ€§èƒ½æŒ‡æ ‡åŸºå‡†çº¿

| æŒ‡æ ‡ç±»å‹ | ç°çŠ¶åŸºçº¿ | ç›®æ ‡å€¼ | éªŒæ”¶æ ‡å‡† | æµ‹è¯•æ–¹æ³• |
|---------|----------|--------|----------|----------|
| **APIå“åº”æ—¶é—´** | 500-800ms | <200ms (P95) | è¿ç»­7å¤©94%ä»¥ä¸Šçš„APIè°ƒç”¨<200ms | AB Testing + Monitoring |
| **å¹¶å‘å¤„ç†èƒ½åŠ›** | 50 tasks | 1000+ tasks | åŒæ—¶å¤„ç†1000ä¸ªæ‰«æä»»åŠ¡æ— å¡é¡¿ | Load Testing |
| **æ•°æ®åº“æŸ¥è¯¢** | 200-500ms | <100ms | å¤æ‚æŸ¥è¯¢P95<100ms | SQL Profiling |
| **å†…å­˜ä½¿ç”¨ç‡** | 60-80% | <60% | å³°å€¼æ—¶åˆ»å†…å­˜ä½¿ç”¨ç‡ä¸è¶…è¿‡60% | System Monitoring |
| **ç¼“å­˜å‘½ä¸­ç‡** | N/A | >80% | çƒ­ç‚¹æ•°æ®ç¼“å­˜å‘½ä¸­ç‡è¶…è¿‡80% | Redis Monitoring |

#### åŠŸèƒ½æŒ‡æ ‡éªŒæ”¶

```mermaid
graph TB
    A[åŠŸèƒ½éªŒæ”¶] --> B[åŸºç¡€åŠŸèƒ½]
    A --> C[é«˜çº§åŠŸèƒ½] 
    A --> D[ä¼ä¸šåŠŸèƒ½]
    
    B --> B1[æ‰«æå¼•æ“ç²¾åº¦>95%]
    B --> B2[ç”¨æˆ·ç•Œé¢å“åº”<3s]
    B --> B3[å®æ—¶é€šçŸ¥å»¶è¿Ÿ<2s]
    
    C --> C1[å¤šAIæ¨¡å‹é›†æˆ]
    C --> C2[å®šæ—¶ä»»åŠ¡è°ƒåº¦]
    C --> C3[è‡ªå®šä¹‰è§„åˆ™å¼•æ“]
    
    D --> D1[å¤šç§Ÿæˆ·æ•°æ®éš”ç¦»]
    D --> D2[APIé™æµä¸é‰´æƒ]
    D3[RBACæƒé™ä½“ç³»]
```

### 10.2 ä¸šåŠ¡æŒ‡æ ‡éªŒæ”¶

#### ç”¨æˆ·ä½“éªŒæŒ‡æ ‡

1. **ä»»åŠ¡åˆ›å»ºæ•ˆç‡** - ä»åˆ›å»ºåˆ°å¼€å§‹æ‰§è¡Œ < 30ç§’
2. **ç»“æœå¯è§†åŒ–** - æŠ¥å‘Šç”Ÿæˆæ—¶é—´ < 5ç§’
3. **é”™è¯¯æ¢å¤** - ç³»ç»Ÿæ•…éšœæ¢å¤æ—¶é—´ < 5åˆ†é’Ÿ
4. **æ•°æ®å‡†ç¡®æ€§** - AIè¯†åˆ«å‡†ç¡®ç‡ > 95% (åŸºäºæµ‹è¯•é›†)
5. **ç³»ç»Ÿå¯ç”¨æ€§** - 99.9% SLA (æœˆåº¦ç»Ÿè®¡)

#### ROI æ•ˆç›Šè¯„ä¼°

**æˆæœ¬æŠ•å…¥åˆ†æ**
```
äººåŠ›æˆæœ¬:
- é«˜çº§å¼€å‘å·¥ç¨‹å¸ˆ Ã— 3äºº Ã— 6ä¸ªæœˆ = 180ä¸‡å…ƒ
- æ¶æ„å¸ˆ Ã— 1äºº Ã— 4ä¸ªæœˆ = 40ä¸‡å…ƒ  
- DevOpså·¥ç¨‹å¸ˆ Ã— 1äºº Ã— 3ä¸ªæœˆ = 24ä¸‡å…ƒ
- QAæµ‹è¯•å·¥ç¨‹å¸ˆ Ã— 1äºº Ã— 4ä¸ªæœˆ = 20ä¸‡å…ƒ

åŸºç¡€è®¾æ–½æˆæœ¬:
- äº‘æœåŠ¡å™¨èµ„æº = 15ä¸‡å…ƒ/å¹´
- ç¬¬ä¸‰æ–¹æœåŠ¡(AI APIç­‰) = 8ä¸‡å…ƒ/å¹´
- ç›‘æ§ä¸è¿ç»´å·¥å…· = 5ä¸‡å…ƒ/å¹´

æ€»æˆæœ¬: 292ä¸‡å…ƒ (ä¸€æ¬¡æ€§) + 28ä¸‡å…ƒ/å¹´ (è¿è¥)
```

**æ•ˆç›Šå›æŠ¥åˆ†æ**
```
ç›´æ¥æ•ˆç›Š:
- æ‰«ææ•ˆç‡æå‡70% â†’ èŠ‚çœäººåŠ›æˆæœ¬ 50ä¸‡å…ƒ/å¹´
- ç³»ç»Ÿæ•…éšœå‡å°‘90% â†’ å‡å°‘ä¸šåŠ¡æŸå¤± 30ä¸‡å…ƒ/å¹´
- è‡ªåŠ¨åŒ–ç¨‹åº¦æå…80% â†’ èŠ‚çœè¿ç»´æˆæœ¬ 25ä¸‡å…ƒ/å¹´

é—´æ¥æ•ˆç›Š:
- æå‡ç”¨æˆ·æ»¡æ„åº¦ â†’ å®¢æˆ·ç•™å­˜ç‡æå‡5%
- å¢å¼ºäº§å“ç«äº‰åŠ› â†’ å¸‚åœºä»½é¢æå‡10%
- æŠ€æœ¬å“ç‰Œå½±å“åŠ› â†’ äººæ‰å¸å¼•ä¸ç•™å­˜

å¹´åŒ–ROI = (ç›´æ¥æ•ˆç›Š 105ä¸‡ - è¿è¥æˆæœ¬ 28ä¸‡) / æŠ•å…¥ 292ä¸‡ = 26.4%
```

### 10.3 æœ€ç»ˆäº¤ä»˜æ¸…å•

#### æŠ€æœ¬äº¤ä»˜ç‰©

- [ ] **æºä»£ç ** - å®Œæ•´çš„é‡æ„åæºä»£ç ï¼ŒåŒ…å«å…¨éƒ¨æ–°åŠŸèƒ½
- [ ] **æ•°æ®åº“è¿ç§»è„šæœ¬** - å®Œæ•´çš„æ•°æ®è¿ç§»å’Œå›æ»šè„šæœ¬
- [ ] **éƒ¨ç½²æ–‡æ¡£** - Docker/K8séƒ¨ç½²æ–‡æ¡£ä¸é…ç½®æ–‡ä»¶
- [ ] **APIæ–‡æ¡£** - å®Œæ•´çš„RESTful APIæ–‡æ¡£å’Œç¤ºä¾‹
- [ ] **ç›‘æ§é…ç½®** - Prometheus/Grafanaç›‘æ§é¢æ¿å’Œå‘Šè­¦è§„åˆ™

#### è¿ç»´äº¤ä»˜ç‰©

- [ ] **è¿ç»´æ‰‹å†Œ** - ç³»ç»Ÿè¿ç»´ã€æ•…éšœæ’æŸ¥ã€åº”æ€¥å¤„ç†æŒ‡å—
- [ ] **æ€§èƒ½è°ƒä¼˜æŒ‡å—** - æ•°æ®åº“ã€ç¼“å­˜ã€åº”ç”¨æ€§èƒ½è°ƒä¼˜æŒ‡å—
- [ ] **å®‰å…¨åŠ å›ºæŒ‡å—** - å®‰å…¨é…ç½®ã€æ¼æ´ä¿®å¤ã€å®‰å…¨æ‰«ææµç¨‹
- [ ] **ç”¨æˆ·æ‰‹å†Œ** - ç®¡ç†å‘˜å’Œæ™®é€šç”¨æˆ·ä½¿ç”¨æŒ‡å—
- [ ] **åŸ¹è®­ææ–™** - æŠ€æœ¯å›¢é˜ŸåŸ¹è®­ææ–™å’Œè§†é¢‘æ•™ç¨‹

#### çŸ¥è¯†è½¬ç§»äº¤ä»˜

- [ ] **æŠ€æœ¯åˆ†äº«** - æ ¸å¿ƒæŠ€æœ¯ç‚¹å’Œæ¶æ„å†³ç­–åˆ†äº«ä¼š
- [ ] **ä»£ç Review** - å…³é”®ä»£ç æ¨¡å—Reviewå’ŒæŠ€æœ¯äº¤æµ  
- [ ] **é—®é¢˜æ¸…å•** - å·²çŸ¥é—®é¢˜ã€é™åˆ¶å’Œåç»­ä¼˜åŒ–å»ºè®®
- [ ] **æŠ€æœ¯è·¯çº¿å›¾** - æœªæ¥æŠ€æœ¬å‘å±•å’Œäº§å“è§„åˆ’è·¯çº¿

---

## æ€»ç»“

æœ¬è®¾è®¡æ–‡æ¡£å…¨é¢åˆ†æäº†AIå†…å®¹å®‰å…¨ç›‘æ§ç³»ç»Ÿçš„ç°çŠ¶ï¼Œå¹¶åˆ¶å®šäº†è¯¦ç»†çš„ä¼˜åŒ–è§„åˆ’ã€‚é€šè¿‡ä¸‰ä¸ªé˜¶æ®µçš„ç³»ç»Ÿæ€§æ”¹è¿›ï¼Œå°†å®ç°ï¼š

**æŠ€æœ¯æ¶æ„è·¨è¶Š** - ä»å•ä½“åº”ç”¨å‡çº§ä¸ºå¾®æœåŠ¡æ¶æ„
**æ€§èƒ½å¤§å¹…æå‡** - ç³»ç»Ÿå¤„ç†èƒ½åŠ›æå‡20å€ï¼Œå“åº”é€Ÿåº¦æå‰70%
**åŠŸèƒ½æ·±åº¦æ‹“å±•** - æ–°å¢ä¼ä¸šçº§ç®¡ç†ã€å¤šAIæ¨¡å‹ã€å®šæ—¶ç›‘æ§ç­‰é«˜çº§åŠŸèƒ½
**ç”¨æˆ·ä½“éªŒä¼˜åŒ–** - æµç¨‹ç®€åŒ–ã€75%ä»¥ä¸Šçš„æ“ä½œç”¨æ—¶ç¼©çŸ­
**ä¼ä¸šçº§èƒ½åŠ›** - å…¨é¢çš„å¤šç§Ÿæˆ·ã€æƒé™ç®¡ç†ã€åˆè§„æŠ¥å‘Šä½“ç³»

æ­¤è§„åˆ’ä¸ä»…è§£å†³äº†å½“å‰çš„æŠ€æœ¯å€ºåŠ¡å’Œæ€§èƒ½ç“¶é¢ˆï¼Œæ›´ä¸ºç³»ç»Ÿçš„é•¿è¿œå‘å±•å¥‹å®šäº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚é¢„æœŸåœ¨å®Œæˆæ‰€æœ‰ä¼˜åŒ–åï¼Œè¯¥ç³»ç»Ÿå°†æˆä¸ºä¸€ä¸ªçœŸæ­£å…·å¤‡ä¼ä¸šçº§èƒ½åŠ›çš„AIå†…å®¹å®‰å…¨ç›‘æ§å¹³å°ã€‚

### 9.4 å®æ–½æˆåŠŸæŒ‡æ ‡

#### æ€§èƒ½æŒ‡æ ‡
- **å“åº”æ—¶é—´**: APIå“åº”æ—¶é—´ < 200ms (P95)
- **å¹¶å‘å¤„ç†**: æ”¯æŒ1000+ å¹¶å‘æ‰«æä»»åŠ¡
- **ç³»ç»Ÿå¯ç”¨æ€§**: 99.9% SLAä¿è¯
- **èµ„æºåˆ©ç”¨ç‡**: CPU/å†…å­˜ä½¿ç”¨ç‡ < 80%

#### ä¸šåŠ¡æŒ‡æ ‡  
- **æ‰«ææ•ˆç‡**: å•ä¸ªåŸŸåæ‰«ææ—¶é—´å‡å°‘50%
- **å‡†ç¡®ç‡**: AIè¯†åˆ«å‡†ç¡®ç‡ > 95%
- **ç”¨æˆ·æ»¡æ„åº¦**: ç”¨æˆ·åé¦ˆè¯„åˆ† > 4.5/5.0
- **ç³»ç»Ÿç¨³å®šæ€§**: æ•…éšœæ¢å¤æ—¶é—´ < 5åˆ†é’Ÿ
```