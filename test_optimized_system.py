#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–çš„æˆªå›¾æœåŠ¡å’ŒAIåˆ†æè¾“å‡ºç®¡ç†å™¨
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.engines.optimized_screenshot_service import OptimizedScreenshotService, DomainScreenshotResult
from app.engines.ai_analysis_output_manager import AIAnalysisOutputManager


async def test_optimized_screenshot_service():
    """æµ‹è¯•ä¼˜åŒ–çš„æˆªå›¾æœåŠ¡"""
    print("=== æµ‹è¯•ä¼˜åŒ–çš„æˆªå›¾æœåŠ¡ ===")
    
    task_id = "test_task_" + str(int(asyncio.get_event_loop().time()))
    
    # æµ‹è¯•åŸŸååˆ—è¡¨
    test_domains = [
        "www.baidu.com",
        "www.github.com", 
        "www.stackoverflow.com"
    ]
    
    try:
        async with OptimizedScreenshotService(task_id, "test_user") as screenshot_service:
            # æµ‹è¯•é…ç½®
            config = {
                'skip_existing': False,  # å¼ºåˆ¶é‡æ–°æˆªå›¾
                'timeout': 30000
            }
            
            print(f"å¼€å§‹æµ‹è¯• {len(test_domains)} ä¸ªåŸŸåçš„æˆªå›¾...")
            
            # æ‰§è¡Œä¼˜åŒ–æˆªå›¾
            results = await screenshot_service.capture_domains_optimized(test_domains, config)
            
            print(f"\næˆªå›¾ç»“æœ:")
            success_count = 0
            for result in results:
                status = "âœ“" if result.success else "âœ—"
                print(f"{status} {result.domain}: {result.error_message if not result.success else f'æˆªå›¾å¤§å°: {result.file_size} bytes'}")
                if result.success:
                    success_count += 1
                    print(f"   æˆªå›¾è·¯å¾„: {result.screenshot_path}")
                    print(f"   æºç è·¯å¾„: {result.source_code_path}")
                    print(f"   é¡µé¢æ ‡é¢˜: {result.page_title}")
                    print(f"   å†…å®¹å“ˆå¸Œ: {result.content_hash}")
            
            print(f"\næˆåŠŸç‡: {success_count}/{len(test_domains)} ({success_count/len(test_domains)*100:.1f}%)")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = screenshot_service.get_statistics()
            print(f"\næœåŠ¡ç»Ÿè®¡:")
            print(f"- æˆªå›¾æ–‡ä»¶æ•°: {stats.get('screenshot_count', 0)}")
            print(f"- æºç æ–‡ä»¶æ•°: {stats.get('source_code_count', 0)}")
            print(f"- ä¸´æ—¶æ–‡ä»¶æ•°: {stats.get('temp_file_count', 0)}")
            print(f"- æˆªå›¾æ€»å¤§å°: {stats.get('total_screenshot_size_mb', 0)} MB")
            print(f"- æºç æ€»å¤§å°: {stats.get('total_source_size_mb', 0)} MB")
            
            # æµ‹è¯•è·å–åˆ†ææ•°æ®
            print(f"\næµ‹è¯•è·å–åˆ†ææ•°æ®:")
            for domain in test_domains[:2]:  # åªæµ‹è¯•å‰ä¸¤ä¸ª
                analysis_data = await screenshot_service.get_domain_analysis_data(domain)
                if analysis_data:
                    print(f"âœ“ {domain}: æ‰¾åˆ°åˆ†ææ•°æ®")
                    print(f"   - æˆªå›¾è·¯å¾„: {analysis_data.get('screenshot_path', 'N/A')}")
                    print(f"   - æºç è·¯å¾„: {analysis_data.get('source_code_path', 'N/A')}")
                    print(f"   - é¡µé¢æ ‡é¢˜: {analysis_data.get('page_title', 'N/A')}")
                else:
                    print(f"âœ— {domain}: æœªæ‰¾åˆ°åˆ†ææ•°æ®")
            
            return True
            
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_ai_analysis_output_manager():
    """æµ‹è¯•AIåˆ†æè¾“å‡ºç®¡ç†å™¨"""
    print("\n=== æµ‹è¯•AIåˆ†æè¾“å‡ºç®¡ç†å™¨ ===")
    
    task_id = "test_task_" + str(int(asyncio.get_event_loop().time()))
    
    try:
        output_manager = AIAnalysisOutputManager(task_id, "test_user")
        
        # æµ‹è¯•æ•°æ®
        test_domain = "example.com"
        screenshot_path = "test_screenshot.png" 
        source_code_path = "test_source.html"
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„æˆªå›¾å’Œæºç æ–‡ä»¶
        test_screenshot_data = b"fake_png_data"
        test_source_code = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>æµ‹è¯•é¡µé¢</title>
            <meta name="description" content="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é¡µé¢">
        </head>
        <body>
            <h1>æµ‹è¯•å†…å®¹</h1>
            <p>è¿™æ˜¯æµ‹è¯•æ–‡æœ¬å†…å®¹</p>
        </body>
        </html>
        """
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_screenshot = Path("temp_test_screenshot.png")
        temp_source = Path("temp_test_source.html")
        
        with open(temp_screenshot, 'wb') as f:
            f.write(test_screenshot_data)
        
        with open(temp_source, 'w', encoding='utf-8') as f:
            f.write(test_source_code)
        
        try:
            print("æµ‹è¯•å‡†å¤‡åˆ†æè¾“å…¥æ–‡ä»¶...")
            
            # å‡†å¤‡åˆ†æè¾“å…¥
            input_file_path = await output_manager.prepare_analysis_input(
                test_domain,
                str(temp_screenshot),
                str(temp_source),
                {"additional_info": "test_data"}
            )
            
            print(f"âœ“ è¾“å…¥æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {input_file_path}")
            
            # éªŒè¯è¾“å…¥æ–‡ä»¶å†…å®¹
            input_data = output_manager.load_input_data(input_file_path)
            if input_data:
                print("âœ“ è¾“å…¥æ–‡ä»¶å†…å®¹éªŒè¯æˆåŠŸ")
                print(f"   - åŸŸå: {input_data.get('domain')}")
                print(f"   - é¡µé¢æ ‡é¢˜: {input_data.get('page_title')}")
                print(f"   - é¡µé¢æè¿°: {input_data.get('page_description')}")
                print(f"   - æºç é•¿åº¦: {input_data.get('source_code_length', 0)}")
                print(f"   - æˆªå›¾å¤§å°: {input_data.get('screenshot_size', 0)}")
            else:
                print("âœ— è¾“å…¥æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥")
                return False
            
            print("\næµ‹è¯•ä¿å­˜åˆ†æè¾“å‡ºæ–‡ä»¶...")
            
            # æ¨¡æ‹ŸAIåˆ†æç»“æœ
            mock_analysis_result = {
                "has_violation": False,
                "violation_types": [],
                "confidence_score": 0.85,
                "risk_level": "low",
                "title": "æµ‹è¯•ç½‘ç«™",
                "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç½‘ç«™ï¼Œæ²¡æœ‰å‘ç°å®‰å…¨é—®é¢˜"
            }
            
            mock_ai_response = '{"success": true, "analysis": "mock_response"}'
            
            # ä¿å­˜åˆ†æè¾“å‡º
            output_file_path = await output_manager.save_analysis_output(
                test_domain,
                mock_analysis_result,
                mock_ai_response,
                input_file_path
            )
            
            print(f"âœ“ è¾“å‡ºæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {output_file_path}")
            
            # æµ‹è¯•åŠ è½½æœ€æ–°åˆ†æç»“æœ
            latest_result = output_manager.load_latest_analysis_result(test_domain)
            if latest_result:
                print("âœ“ æœ€æ–°åˆ†æç»“æœåŠ è½½æˆåŠŸ")
                print(f"   - æœ‰è¿è§„: {latest_result.get('processing_info', {}).get('has_violation', False)}")
                print(f"   - ç½®ä¿¡åº¦: {latest_result.get('processing_info', {}).get('confidence_score', 0)}")
                print(f"   - é£é™©ç­‰çº§: {latest_result.get('processing_info', {}).get('risk_level', 'unknown')}")
            else:
                print("âœ— æœ€æ–°åˆ†æç»“æœåŠ è½½å¤±è´¥")
                return False
            
            # è·å–åˆ†ææ‘˜è¦
            summary = output_manager.get_analysis_summary()
            print(f"\nåˆ†ææ‘˜è¦:")
            print(f"- è¾“å…¥æ–‡ä»¶æ•°: {summary.get('total_input_files', 0)}")
            print(f"- è¾“å‡ºæ–‡ä»¶æ•°: {summary.get('total_output_files', 0)}")
            print(f"- æ€»åˆ†ææ•°: {summary.get('total_analyzed', 0)}")
            print(f"- è¿è§„æ•°é‡: {summary.get('violation_count', 0)}")
            print(f"- è¿è§„ç‡: {summary.get('violation_rate', 0)}%")
            
            return True
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in [temp_screenshot, temp_source]:
                if temp_file.exists():
                    temp_file.unlink()
    
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_integration():
    """æµ‹è¯•æ•´åˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ•´åˆåŠŸèƒ½ ===")
    
    task_id = "integration_test_" + str(int(asyncio.get_event_loop().time()))
    
    try:
        # æµ‹è¯•åŸŸå
        test_domain = "httpbin.org"  # ä¸€ä¸ªç¨³å®šçš„æµ‹è¯•APIç½‘ç«™
        
        print(f"æµ‹è¯•åŸŸå: {test_domain}")
        
        # 1. æˆªå›¾æœåŠ¡
        async with OptimizedScreenshotService(task_id, "test_user") as screenshot_service:
            config = {'skip_existing': False}
            
            print("æ­¥éª¤1: æ‰§è¡Œæˆªå›¾...")
            results = await screenshot_service.capture_domains_optimized([test_domain], config)
            
            if not results or not results[0].success:
                print("âœ— æˆªå›¾å¤±è´¥")
                return False
            
            result = results[0]
            print(f"âœ“ æˆªå›¾æˆåŠŸ: {result.screenshot_path}")
            
            # 2. AIåˆ†æè¾“å‡ºç®¡ç†
            output_manager = AIAnalysisOutputManager(task_id, "test_user")
            
            print("æ­¥éª¤2: å‡†å¤‡AIåˆ†æè¾“å…¥...")
            input_file_path = await output_manager.prepare_analysis_input(
                test_domain,
                result.screenshot_path,
                result.source_code_path
            )
            print(f"âœ“ AIè¾“å…¥æ–‡ä»¶: {input_file_path}")
            
            # 3. æ¨¡æ‹ŸAIåˆ†æ
            print("æ­¥éª¤3: æ¨¡æ‹ŸAIåˆ†æ...")
            mock_result = {
                "has_violation": False,
                "violation_types": [],
                "confidence_score": 0.9,
                "risk_level": "low",
                "title": "æµ‹è¯•ç½‘ç«™å®‰å…¨æ£€æŸ¥",
                "description": "ç½‘ç«™å†…å®¹æ­£å¸¸ï¼Œæœªå‘ç°å®‰å…¨é—®é¢˜"
            }
            
            output_file_path = await output_manager.save_analysis_output(
                test_domain,
                mock_result,
                '{"mock": "ai_response"}',
                input_file_path
            )
            print(f"âœ“ AIè¾“å‡ºæ–‡ä»¶: {output_file_path}")
            
            # 4. éªŒè¯å®Œæ•´æµç¨‹
            analysis_data = await screenshot_service.get_domain_analysis_data(test_domain)
            if analysis_data:
                print("âœ“ å®Œæ•´æµç¨‹éªŒè¯æˆåŠŸ")
                print(f"   - æˆªå›¾æ–‡ä»¶: {Path(analysis_data['screenshot_path']).exists()}")
                print(f"   - æºç æ–‡ä»¶: {Path(analysis_data['source_code_path']).exists() if analysis_data.get('source_code_path') else False}")
                print(f"   - ä¸´æ—¶æ–‡ä»¶: {Path(analysis_data['temp_analysis_path']).exists() if analysis_data.get('temp_analysis_path') else False}")
            else:
                print("âœ— å®Œæ•´æµç¨‹éªŒè¯å¤±è´¥")
                return False
            
            return True
    
    except Exception as e:
        print(f"æ•´åˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¼˜åŒ–çš„æˆªå›¾å’ŒAIåˆ†æç³»ç»Ÿ")
    print("=" * 60)
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        ("ä¼˜åŒ–æˆªå›¾æœåŠ¡", test_optimized_screenshot_service),
        ("AIåˆ†æè¾“å‡ºç®¡ç†å™¨", test_ai_analysis_output_manager),
        ("æ•´åˆåŠŸèƒ½", test_integration)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            print(f"\nğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
            success = await test_func()
            results.append((test_name, success))
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"æµ‹è¯•ç»“æœ: {status}")
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_name} å‡ºç°å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ…" if success else "âŒ"
        print(f"{status} {test_name}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é€šè¿‡ ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¼˜åŒ–æ–¹æ¡ˆå·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")


if __name__ == "__main__":
    asyncio.run(main())